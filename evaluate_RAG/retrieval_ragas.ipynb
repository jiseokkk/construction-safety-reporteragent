{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7caf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctitle</th>\n",
       "      <th>question</th>\n",
       "      <th>chunk</th>\n",
       "      <th>retrieval_result</th>\n",
       "      <th>hit</th>\n",
       "      <th>selected_dbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨</td>\n",
       "      <td>ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”</td>\n",
       "      <td>ì´ì§€ì¹¨ì€êµëŸ‰í˜•ì‹ì¤‘ì£¼íƒ‘ì—ê²½ì‚¬ì§€ê²Œì„¤ì¹˜ëœì¼€ì´ë¸”ë¡œêµëŸ‰ì˜ìƒíŒì„ì—°ê²° ì§€ì§€í•˜ëŠ”í˜•ì‹ì¸ì‚¬ì¥êµì˜ì•ˆì „í•œ...</td>\n",
       "      <td>['ì´ì§€ì¹¨ì€ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™(ì´í•˜â€œì•ˆì „ë³´ê±´ê·œì¹™â€ì´ë¼í•œë‹¤) ì œ56ì¡° ì˜ê·œì •(ì‘...</td>\n",
       "      <td>False</td>\n",
       "      <td>['01_bridge']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>êµëŸ‰ê³µì‚¬ì˜ ì´ë™ì‹ ë¹„ê³„ê³µë²•(MSS) ì•ˆì „ì‘ì—… ì§€ì¹¨</td>\n",
       "      <td>ì´ë™ì‹ ë¹„ê³„(MSS)ì˜ ì •ì˜ì™€ ë°©ì‹ì— ë”°ë¥¸ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©í•˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œì´ë™ì‹ë¹„ê³„(Mo...</td>\n",
       "      <td>['(6) ì´ë™ëŒ€ì°¨ëŠ”ì¸ì–‘í•˜ì—¬êµê°ë¸Œë¼ì¼“ìƒë¶€ì˜ë ˆì¼ìœ„ì—ì°¨ë¥œì´ë†“ì´ë„ë¡ì„¤ì¹˜ í•˜ê³ ì´ë™ëŒ€ì°¨ê°€ë¶ˆì‹œ...</td>\n",
       "      <td>False</td>\n",
       "      <td>['04_scaffold', '01_bridge']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ê°•ì•„ì¹˜êµ(ë²¤íŠ¸ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨</td>\n",
       "      <td>ê°•ì•„ì¹˜êµì—ì„œ ì•„ì¹˜ë¦¬ë¸Œ(Rib)ë€ ë¬´ì—‡ì´ë©° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ëœ»ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œê°•ì•„ì¹˜êµâ€ë¼í•¨ì€ì£¼...</td>\n",
       "      <td>['(ë‚˜) â€œì£¼íƒ‘(Pylon)â€ì´ë¼í•¨ì€ì‚¬ì¥êµì™€ë§ˆì°¬ê°€ì§€ë¡œì£¼ì¼€ì´ë¸”ì˜í•˜ì¤‘ì„ê¸°ì´ˆì— ì „ë‹¬í•˜ëŠ”...</td>\n",
       "      <td>False</td>\n",
       "      <td>['01_bridge']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCTê±°ë” êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨</td>\n",
       "      <td>PCTê±°ë”êµì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</td>\n",
       "      <td>(1) PCTê±°ë”êµì˜ì£¼ìš”íŠ¹ì§•ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) ì¢…ë‹¨ë°í‰ë©´ì„ í˜•ì—ì œì•½ì„ë°›...</td>\n",
       "      <td>['(1) ìŠ¬ë¼ì´ë”©íŒ¨ë“œëŠ”ì œì‘ì¥, íš¡ë°©í–¥ê°€ì´ë“œ, êµëŒ€ë°êµê°, ì¶”ì§„ì½”ì—°ê²°ê±°ë”ë“± ì—ë§ëŠ”ì ...</td>\n",
       "      <td>False</td>\n",
       "      <td>['01_bridge']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>í˜„ìˆ˜êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨</td>\n",
       "      <td>í˜„ìˆ˜êµ(Suspension bridge)ë€ ì–´ë–¤ êµëŸ‰ í˜•ì‹ì„ ë§í•˜ë‚˜ìš”?</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œí˜„ìˆ˜êµ(Susp...</td>\n",
       "      <td>['(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤. (ê°€) â€œí˜„ìˆ˜êµ(Suspensio...</td>\n",
       "      <td>False</td>\n",
       "      <td>['01_bridge']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doctitle                                 question  \\\n",
       "0           ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨            ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”   \n",
       "1  êµëŸ‰ê³µì‚¬ì˜ ì´ë™ì‹ ë¹„ê³„ê³µë²•(MSS) ì•ˆì „ì‘ì—… ì§€ì¹¨       ì´ë™ì‹ ë¹„ê³„(MSS)ì˜ ì •ì˜ì™€ ë°©ì‹ì— ë”°ë¥¸ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?   \n",
       "2          ê°•ì•„ì¹˜êµ(ë²¤íŠ¸ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨       ê°•ì•„ì¹˜êµì—ì„œ ì•„ì¹˜ë¦¬ë¸Œ(Rib)ë€ ë¬´ì—‡ì´ë©° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?   \n",
       "3          PCTê±°ë” êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨                PCTê±°ë”êµì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?   \n",
       "4           í˜„ìˆ˜êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨  í˜„ìˆ˜êµ(Suspension bridge)ë€ ì–´ë–¤ êµëŸ‰ í˜•ì‹ì„ ë§í•˜ë‚˜ìš”?   \n",
       "\n",
       "                                               chunk  \\\n",
       "0  ì´ì§€ì¹¨ì€êµëŸ‰í˜•ì‹ì¤‘ì£¼íƒ‘ì—ê²½ì‚¬ì§€ê²Œì„¤ì¹˜ëœì¼€ì´ë¸”ë¡œêµëŸ‰ì˜ìƒíŒì„ì—°ê²° ì§€ì§€í•˜ëŠ”í˜•ì‹ì¸ì‚¬ì¥êµì˜ì•ˆì „í•œ...   \n",
       "1  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©í•˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œì´ë™ì‹ë¹„ê³„(Mo...   \n",
       "2  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ëœ»ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œê°•ì•„ì¹˜êµâ€ë¼í•¨ì€ì£¼...   \n",
       "3  (1) PCTê±°ë”êµì˜ì£¼ìš”íŠ¹ì§•ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) ì¢…ë‹¨ë°í‰ë©´ì„ í˜•ì—ì œì•½ì„ë°›...   \n",
       "4  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œí˜„ìˆ˜êµ(Susp...   \n",
       "\n",
       "                                    retrieval_result    hit  \\\n",
       "0  ['ì´ì§€ì¹¨ì€ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™(ì´í•˜â€œì•ˆì „ë³´ê±´ê·œì¹™â€ì´ë¼í•œë‹¤) ì œ56ì¡° ì˜ê·œì •(ì‘...  False   \n",
       "1  ['(6) ì´ë™ëŒ€ì°¨ëŠ”ì¸ì–‘í•˜ì—¬êµê°ë¸Œë¼ì¼“ìƒë¶€ì˜ë ˆì¼ìœ„ì—ì°¨ë¥œì´ë†“ì´ë„ë¡ì„¤ì¹˜ í•˜ê³ ì´ë™ëŒ€ì°¨ê°€ë¶ˆì‹œ...  False   \n",
       "2  ['(ë‚˜) â€œì£¼íƒ‘(Pylon)â€ì´ë¼í•¨ì€ì‚¬ì¥êµì™€ë§ˆì°¬ê°€ì§€ë¡œì£¼ì¼€ì´ë¸”ì˜í•˜ì¤‘ì„ê¸°ì´ˆì— ì „ë‹¬í•˜ëŠ”...  False   \n",
       "3  ['(1) ìŠ¬ë¼ì´ë”©íŒ¨ë“œëŠ”ì œì‘ì¥, íš¡ë°©í–¥ê°€ì´ë“œ, êµëŒ€ë°êµê°, ì¶”ì§„ì½”ì—°ê²°ê±°ë”ë“± ì—ë§ëŠ”ì ...  False   \n",
       "4  ['(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤. (ê°€) â€œí˜„ìˆ˜êµ(Suspensio...  False   \n",
       "\n",
       "                   selected_dbs  \n",
       "0                 ['01_bridge']  \n",
       "1  ['04_scaffold', '01_bridge']  \n",
       "2                 ['01_bridge']  \n",
       "3                 ['01_bridge']  \n",
       "4                 ['01_bridge']  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv('/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/evaluate_RAG/llm_multidb_retrieval_result.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504cc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§€ì„ - retriever.py\n",
    "\n",
    "\n",
    "# import os\n",
    "# import re\n",
    "# from typing import List, Dict, Any\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "# from langchain.schema import Document\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_community.embeddings import OpenAIEmbeddings\n",
    "# from langchain_community.retrievers import BM25Retriever\n",
    "# from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "# from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "\n",
    "\n",
    "# def get_qwen_api_embeddings():\n",
    "#     embedder_model_name = \"Qwen/Qwen3-Embedding-4B\"\n",
    "#     embedder_base_url = \"http://211.47.56.71:15653/v1\"\n",
    "#     embedder_api_key = \"token-abc123\"\n",
    "\n",
    "#     return OpenAIEmbeddings(\n",
    "#         model=embedder_model_name,\n",
    "#         base_url=embedder_base_url,\n",
    "#         api_key=embedder_api_key,\n",
    "#     )\n",
    "\n",
    "\n",
    "# def _clean_text(text: str) -> str:\n",
    "#     text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "#     text = re.sub(r\"\\s+\", \" \", text)\n",
    "#     return text.strip()\n",
    "\n",
    "\n",
    "# class SingleDBHybridRetriever:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         db_dir: str,\n",
    "#         top_k: int = 20,\n",
    "#         alpha: float = 0.3,\n",
    "#         rerank_top_n: int = 5,\n",
    "#         reranker_model: str = \"BAAI/bge-reranker-v2-m3\"\n",
    "#     ):\n",
    "#         self.db_dir = db_dir\n",
    "#         self.top_k = top_k\n",
    "#         self.alpha = alpha\n",
    "#         self.rerank_top_n = rerank_top_n\n",
    "#         self.reranker_model = reranker_model\n",
    "\n",
    "#         print(f\"ğŸ“‚ HybridRetriever ì´ˆê¸°í™”: {db_dir}\")\n",
    "\n",
    "#         # 1) load FAISS\n",
    "#         self.embeddings = get_qwen_api_embeddings()\n",
    "#         self.vector_db = FAISS.load_local(\n",
    "#             db_dir, self.embeddings, allow_dangerous_deserialization=True\n",
    "#         )\n",
    "\n",
    "#         # BM25ë¥¼ ìœ„í•œ ì „ì²´ ë¬¸ì„œ ë¡œë“œ\n",
    "#         self.all_docs = list(self.vector_db.docstore._dict.values())\n",
    "\n",
    "#         # ğŸ”¥ Rerankerë¥¼ ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”\n",
    "#         print(f\"ğŸ”„ Reranker ëª¨ë¸ ë¡œë”©: {reranker_model}\")\n",
    "#         self.reranker = HuggingFaceCrossEncoder(model_name=reranker_model)\n",
    "#         self.compressor = CrossEncoderReranker(model=self.reranker, top_n=rerank_top_n)\n",
    "#         print(f\"âœ… Reranker ë¡œë”© ì™„ë£Œ\")\n",
    "\n",
    "#     def _hybrid_merge(self, dense_results, sparse_results):\n",
    "#         dense_dict = {hash(doc.page_content): score for doc, score in dense_results}\n",
    "#         sparse_dict = {hash(doc.page_content): i for i, doc in enumerate(sparse_results)}\n",
    "\n",
    "#         merged = []\n",
    "#         for doc, ds in dense_results:\n",
    "#             h = hash(doc.page_content)\n",
    "#             sr = sparse_dict.get(h, len(sparse_results))\n",
    "#             score = self.alpha * ds + (1 - self.alpha) * (1 - sr / len(sparse_results))\n",
    "#             merged.append((doc, score))\n",
    "\n",
    "#         for i, doc in enumerate(sparse_results):\n",
    "#             h = hash(doc.page_content)\n",
    "#             if h not in dense_dict:\n",
    "#                 score = (1 - self.alpha) * (1 - i / len(sparse_results))\n",
    "#                 merged.append((doc, score))\n",
    "\n",
    "#         merged.sort(key=lambda x: x[1], reverse=True)\n",
    "#         return [doc for doc, _ in merged]\n",
    "\n",
    "#     def retrieve(self, query: str) -> List[Document]:\n",
    "#         print(f\"\\nğŸ” [HybridRetriever] Query: {query}\")\n",
    "\n",
    "#         # 1) Dense(AI semantic)\n",
    "#         dense = self.vector_db.similarity_search_with_score(query, k=self.top_k)\n",
    "\n",
    "#         # 2) Sparse(keyword)\n",
    "#         sparse_retriever = BM25Retriever.from_documents(self.all_docs)\n",
    "#         sparse_retriever.k = self.top_k * 4\n",
    "#         sparse = sparse_retriever.get_relevant_documents(query)\n",
    "\n",
    "#         # 3) Hybrid merge\n",
    "#         hybrid_docs = self._hybrid_merge(dense, sparse)\n",
    "\n",
    "#         # 4) Rerank - ì´ë¯¸ ì´ˆê¸°í™”ëœ compressor ì‚¬ìš©\n",
    "#         reranked = self.compressor.compress_documents(hybrid_docs, query)\n",
    "\n",
    "#         # 5) Clean & return top_k\n",
    "#         final_docs = []\n",
    "#         for d in reranked[: self.top_k]:\n",
    "#             d.page_content = _clean_text(d.page_content)\n",
    "#             final_docs.append(d)\n",
    "\n",
    "#         print(f\"ğŸ“Š ìµœì¢… ë°˜í™˜ ë¬¸ì„œ: {len(final_docs)}ê°œ\")\n",
    "#         return final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f16c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctitle</th>\n",
       "      <th>question</th>\n",
       "      <th>chunk</th>\n",
       "      <th>retrieval_result</th>\n",
       "      <th>hit</th>\n",
       "      <th>selected_dbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨</td>\n",
       "      <td>ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”</td>\n",
       "      <td>ì´ì§€ì¹¨ì€êµëŸ‰í˜•ì‹ì¤‘ì£¼íƒ‘ì—ê²½ì‚¬ì§€ê²Œì„¤ì¹˜ëœì¼€ì´ë¸”ë¡œêµëŸ‰ì˜ìƒíŒì„ì—°ê²° ì§€ì§€í•˜ëŠ”í˜•ì‹ì¸ì‚¬ì¥êµì˜ì•ˆì „í•œ...</td>\n",
       "      <td>['ì´ì§€ì¹¨ì€ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™(ì´í•˜â€œì•ˆì „ë³´ê±´ê·œì¹™â€ì´ë¼í•œë‹¤) ì œ56ì¡° ì˜ê·œì •(ì‘...</td>\n",
       "      <td>False</td>\n",
       "      <td>['01_bridge']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>êµëŸ‰ê³µì‚¬ì˜ ì´ë™ì‹ ë¹„ê³„ê³µë²•(MSS) ì•ˆì „ì‘ì—… ì§€ì¹¨</td>\n",
       "      <td>ì´ë™ì‹ ë¹„ê³„(MSS)ì˜ ì •ì˜ì™€ ë°©ì‹ì— ë”°ë¥¸ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©í•˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œì´ë™ì‹ë¹„ê³„(Mo...</td>\n",
       "      <td>['(6) ì´ë™ëŒ€ì°¨ëŠ”ì¸ì–‘í•˜ì—¬êµê°ë¸Œë¼ì¼“ìƒë¶€ì˜ë ˆì¼ìœ„ì—ì°¨ë¥œì´ë†“ì´ë„ë¡ì„¤ì¹˜ í•˜ê³ ì´ë™ëŒ€ì°¨ê°€ë¶ˆì‹œ...</td>\n",
       "      <td>False</td>\n",
       "      <td>['04_scaffold', '01_bridge']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ê°•ì•„ì¹˜êµ(ë²¤íŠ¸ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨</td>\n",
       "      <td>ê°•ì•„ì¹˜êµì—ì„œ ì•„ì¹˜ë¦¬ë¸Œ(Rib)ë€ ë¬´ì—‡ì´ë©° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ëœ»ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œê°•ì•„ì¹˜êµâ€ë¼í•¨ì€ì£¼...</td>\n",
       "      <td>['(ë‚˜) â€œì£¼íƒ‘(Pylon)â€ì´ë¼í•¨ì€ì‚¬ì¥êµì™€ë§ˆì°¬ê°€ì§€ë¡œì£¼ì¼€ì´ë¸”ì˜í•˜ì¤‘ì„ê¸°ì´ˆì— ì „ë‹¬í•˜ëŠ”...</td>\n",
       "      <td>False</td>\n",
       "      <td>['01_bridge']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCTê±°ë” êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨</td>\n",
       "      <td>PCTê±°ë”êµì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</td>\n",
       "      <td>(1) PCTê±°ë”êµì˜ì£¼ìš”íŠ¹ì§•ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) ì¢…ë‹¨ë°í‰ë©´ì„ í˜•ì—ì œì•½ì„ë°›...</td>\n",
       "      <td>['(1) ìŠ¬ë¼ì´ë”©íŒ¨ë“œëŠ”ì œì‘ì¥, íš¡ë°©í–¥ê°€ì´ë“œ, êµëŒ€ë°êµê°, ì¶”ì§„ì½”ì—°ê²°ê±°ë”ë“± ì—ë§ëŠ”ì ...</td>\n",
       "      <td>False</td>\n",
       "      <td>['01_bridge']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>í˜„ìˆ˜êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨</td>\n",
       "      <td>í˜„ìˆ˜êµ(Suspension bridge)ë€ ì–´ë–¤ êµëŸ‰ í˜•ì‹ì„ ë§í•˜ë‚˜ìš”?</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œí˜„ìˆ˜êµ(Susp...</td>\n",
       "      <td>['(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤. (ê°€) â€œí˜„ìˆ˜êµ(Suspensio...</td>\n",
       "      <td>False</td>\n",
       "      <td>['01_bridge']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doctitle                                 question  \\\n",
       "0           ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨            ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”   \n",
       "1  êµëŸ‰ê³µì‚¬ì˜ ì´ë™ì‹ ë¹„ê³„ê³µë²•(MSS) ì•ˆì „ì‘ì—… ì§€ì¹¨       ì´ë™ì‹ ë¹„ê³„(MSS)ì˜ ì •ì˜ì™€ ë°©ì‹ì— ë”°ë¥¸ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?   \n",
       "2          ê°•ì•„ì¹˜êµ(ë²¤íŠ¸ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨       ê°•ì•„ì¹˜êµì—ì„œ ì•„ì¹˜ë¦¬ë¸Œ(Rib)ë€ ë¬´ì—‡ì´ë©° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?   \n",
       "3          PCTê±°ë” êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨                PCTê±°ë”êµì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?   \n",
       "4           í˜„ìˆ˜êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨  í˜„ìˆ˜êµ(Suspension bridge)ë€ ì–´ë–¤ êµëŸ‰ í˜•ì‹ì„ ë§í•˜ë‚˜ìš”?   \n",
       "\n",
       "                                               chunk  \\\n",
       "0  ì´ì§€ì¹¨ì€êµëŸ‰í˜•ì‹ì¤‘ì£¼íƒ‘ì—ê²½ì‚¬ì§€ê²Œì„¤ì¹˜ëœì¼€ì´ë¸”ë¡œêµëŸ‰ì˜ìƒíŒì„ì—°ê²° ì§€ì§€í•˜ëŠ”í˜•ì‹ì¸ì‚¬ì¥êµì˜ì•ˆì „í•œ...   \n",
       "1  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©í•˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œì´ë™ì‹ë¹„ê³„(Mo...   \n",
       "2  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ëœ»ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œê°•ì•„ì¹˜êµâ€ë¼í•¨ì€ì£¼...   \n",
       "3  (1) PCTê±°ë”êµì˜ì£¼ìš”íŠ¹ì§•ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) ì¢…ë‹¨ë°í‰ë©´ì„ í˜•ì—ì œì•½ì„ë°›...   \n",
       "4  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œí˜„ìˆ˜êµ(Susp...   \n",
       "\n",
       "                                    retrieval_result    hit  \\\n",
       "0  ['ì´ì§€ì¹¨ì€ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™(ì´í•˜â€œì•ˆì „ë³´ê±´ê·œì¹™â€ì´ë¼í•œë‹¤) ì œ56ì¡° ì˜ê·œì •(ì‘...  False   \n",
       "1  ['(6) ì´ë™ëŒ€ì°¨ëŠ”ì¸ì–‘í•˜ì—¬êµê°ë¸Œë¼ì¼“ìƒë¶€ì˜ë ˆì¼ìœ„ì—ì°¨ë¥œì´ë†“ì´ë„ë¡ì„¤ì¹˜ í•˜ê³ ì´ë™ëŒ€ì°¨ê°€ë¶ˆì‹œ...  False   \n",
       "2  ['(ë‚˜) â€œì£¼íƒ‘(Pylon)â€ì´ë¼í•¨ì€ì‚¬ì¥êµì™€ë§ˆì°¬ê°€ì§€ë¡œì£¼ì¼€ì´ë¸”ì˜í•˜ì¤‘ì„ê¸°ì´ˆì— ì „ë‹¬í•˜ëŠ”...  False   \n",
       "3  ['(1) ìŠ¬ë¼ì´ë”©íŒ¨ë“œëŠ”ì œì‘ì¥, íš¡ë°©í–¥ê°€ì´ë“œ, êµëŒ€ë°êµê°, ì¶”ì§„ì½”ì—°ê²°ê±°ë”ë“± ì—ë§ëŠ”ì ...  False   \n",
       "4  ['(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤. (ê°€) â€œí˜„ìˆ˜êµ(Suspensio...  False   \n",
       "\n",
       "                   selected_dbs  \n",
       "0                 ['01_bridge']  \n",
       "1  ['04_scaffold', '01_bridge']  \n",
       "2                 ['01_bridge']  \n",
       "3                 ['01_bridge']  \n",
       "4                 ['01_bridge']  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/evaluate_RAG/llm_multidb_retrieval_result.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0321f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”</td>\n",
       "      <td>[ì´ì§€ì¹¨ì€ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™(ì´í•˜â€œì•ˆì „ë³´ê±´ê·œì¹™â€ì´ë¼í•œë‹¤) ì œ56ì¡° ì˜ê·œì •(ì‘ì—…...</td>\n",
       "      <td>ì´ì§€ì¹¨ì€êµëŸ‰í˜•ì‹ì¤‘ì£¼íƒ‘ì—ê²½ì‚¬ì§€ê²Œì„¤ì¹˜ëœì¼€ì´ë¸”ë¡œêµëŸ‰ì˜ìƒíŒì„ì—°ê²° ì§€ì§€í•˜ëŠ”í˜•ì‹ì¸ì‚¬ì¥êµì˜ì•ˆì „í•œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì´ë™ì‹ ë¹„ê³„(MSS)ì˜ ì •ì˜ì™€ ë°©ì‹ì— ë”°ë¥¸ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</td>\n",
       "      <td>[(6) ì´ë™ëŒ€ì°¨ëŠ”ì¸ì–‘í•˜ì—¬êµê°ë¸Œë¼ì¼“ìƒë¶€ì˜ë ˆì¼ìœ„ì—ì°¨ë¥œì´ë†“ì´ë„ë¡ì„¤ì¹˜ í•˜ê³ ì´ë™ëŒ€ì°¨ê°€ë¶ˆì‹œì—...</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©í•˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œì´ë™ì‹ë¹„ê³„(Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ê°•ì•„ì¹˜êµì—ì„œ ì•„ì¹˜ë¦¬ë¸Œ(Rib)ë€ ë¬´ì—‡ì´ë©° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?</td>\n",
       "      <td>[(ë‚˜) â€œì£¼íƒ‘(Pylon)â€ì´ë¼í•¨ì€ì‚¬ì¥êµì™€ë§ˆì°¬ê°€ì§€ë¡œì£¼ì¼€ì´ë¸”ì˜í•˜ì¤‘ì„ê¸°ì´ˆì— ì „ë‹¬í•˜ëŠ”ì—­...</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ëœ»ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œê°•ì•„ì¹˜êµâ€ë¼í•¨ì€ì£¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCTê±°ë”êµì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</td>\n",
       "      <td>[(1) ìŠ¬ë¼ì´ë”©íŒ¨ë“œëŠ”ì œì‘ì¥, íš¡ë°©í–¥ê°€ì´ë“œ, êµëŒ€ë°êµê°, ì¶”ì§„ì½”ì—°ê²°ê±°ë”ë“± ì—ë§ëŠ”ì ì •...</td>\n",
       "      <td>(1) PCTê±°ë”êµì˜ì£¼ìš”íŠ¹ì§•ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) ì¢…ë‹¨ë°í‰ë©´ì„ í˜•ì—ì œì•½ì„ë°›...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>í˜„ìˆ˜êµ(Suspension bridge)ë€ ì–´ë–¤ êµëŸ‰ í˜•ì‹ì„ ë§í•˜ë‚˜ìš”?</td>\n",
       "      <td>[(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤. (ê°€) â€œí˜„ìˆ˜êµ(Suspension...</td>\n",
       "      <td>(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œí˜„ìˆ˜êµ(Susp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question  \\\n",
       "0            ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”   \n",
       "1       ì´ë™ì‹ ë¹„ê³„(MSS)ì˜ ì •ì˜ì™€ ë°©ì‹ì— ë”°ë¥¸ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?   \n",
       "2       ê°•ì•„ì¹˜êµì—ì„œ ì•„ì¹˜ë¦¬ë¸Œ(Rib)ë€ ë¬´ì—‡ì´ë©° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?   \n",
       "3                PCTê±°ë”êµì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?   \n",
       "4  í˜„ìˆ˜êµ(Suspension bridge)ë€ ì–´ë–¤ êµëŸ‰ í˜•ì‹ì„ ë§í•˜ë‚˜ìš”?   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ì´ì§€ì¹¨ì€ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™(ì´í•˜â€œì•ˆì „ë³´ê±´ê·œì¹™â€ì´ë¼í•œë‹¤) ì œ56ì¡° ì˜ê·œì •(ì‘ì—…...   \n",
       "1  [(6) ì´ë™ëŒ€ì°¨ëŠ”ì¸ì–‘í•˜ì—¬êµê°ë¸Œë¼ì¼“ìƒë¶€ì˜ë ˆì¼ìœ„ì—ì°¨ë¥œì´ë†“ì´ë„ë¡ì„¤ì¹˜ í•˜ê³ ì´ë™ëŒ€ì°¨ê°€ë¶ˆì‹œì—...   \n",
       "2  [(ë‚˜) â€œì£¼íƒ‘(Pylon)â€ì´ë¼í•¨ì€ì‚¬ì¥êµì™€ë§ˆì°¬ê°€ì§€ë¡œì£¼ì¼€ì´ë¸”ì˜í•˜ì¤‘ì„ê¸°ì´ˆì— ì „ë‹¬í•˜ëŠ”ì—­...   \n",
       "3  [(1) ìŠ¬ë¼ì´ë”©íŒ¨ë“œëŠ”ì œì‘ì¥, íš¡ë°©í–¥ê°€ì´ë“œ, êµëŒ€ë°êµê°, ì¶”ì§„ì½”ì—°ê²°ê±°ë”ë“± ì—ë§ëŠ”ì ì •...   \n",
       "4  [(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤. (ê°€) â€œí˜„ìˆ˜êµ(Suspension...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  ì´ì§€ì¹¨ì€êµëŸ‰í˜•ì‹ì¤‘ì£¼íƒ‘ì—ê²½ì‚¬ì§€ê²Œì„¤ì¹˜ëœì¼€ì´ë¸”ë¡œêµëŸ‰ì˜ìƒíŒì„ì—°ê²° ì§€ì§€í•˜ëŠ”í˜•ì‹ì¸ì‚¬ì¥êµì˜ì•ˆì „í•œ...  \n",
       "1  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©í•˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œì´ë™ì‹ë¹„ê³„(Mo...  \n",
       "2  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ëœ»ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œê°•ì•„ì¹˜êµâ€ë¼í•¨ì€ì£¼...  \n",
       "3  (1) PCTê±°ë”êµì˜ì£¼ìš”íŠ¹ì§•ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) ì¢…ë‹¨ë°í‰ë©´ì„ í˜•ì—ì œì•½ì„ë°›...  \n",
       "4  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œí˜„ìˆ˜êµ(Susp...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # question\n",
    "# # contexts (Retrieverê°€ ì‹¤ì œë¡œ Top-kë¡œ ê°€ì ¸ì˜¨ chunkë“¤)\n",
    "# # ground_truth   ì‚¬ëŒì´ ë§Œë“  ê¸°ì¤€ ì •ë‹µ)\n",
    "\n",
    "# import ast\n",
    "\n",
    "\n",
    "# df1 = df[['question', 'retrieval_result', 'chunk']].rename(\n",
    "#     columns={\n",
    "#         'retrieval_result': 'contexts',\n",
    "#         'chunk': 'ground_truth'\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# df1['contexts'] = df1['contexts'].apply(ast.literal_eval)\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c34020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas\n",
      "  Downloading ragas-0.3.9-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.21.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (2.2.6)\n",
      "Requirement already satisfied: datasets>=4.0.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (0.11.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (1.6.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting diskcache>=5.6.3 (from ragas)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting typer (from ragas)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: rich in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (14.1.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (1.107.3)\n",
      "Requirement already satisfied: tqdm in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (4.67.1)\n",
      "Collecting instructor (from ragas)\n",
      "  Downloading instructor-1.13.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitpython (from ragas)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pillow>=10.4.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (11.3.0)\n",
      "Requirement already satisfied: networkx in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (3.4.2)\n",
      "Collecting scikit-network (from ragas)\n",
      "  Downloading scikit_network-0.33.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: langchain in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (0.3.76)\n",
      "Requirement already satisfied: langchain-community in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (0.3.29)\n",
      "Requirement already satisfied: langchain_openai in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from ragas) (0.3.33)\n",
      "Requirement already satisfied: filelock in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (2.32.5)\n",
      "Requirement already satisfied: xxhash in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (1.0.0rc6)\n",
      "Requirement already satisfied: packaging in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from datasets>=4.0.0->ragas) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (3.10)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (0.28.1)\n",
      "Requirement already satisfied: typer-slim in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (0.20.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (1.1.9)\n",
      "Requirement already satisfied: anyio in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (4.10.0)\n",
      "Requirement already satisfied: certifi in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from openai>=1.0.0->ragas) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets>=4.0.0->ragas) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from pydantic>=2.0.0->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from pydantic>=2.0.0->ragas) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=4.0.0->ragas) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=4.0.0->ragas) (2.5.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->ragas)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->ragas)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->ragas)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from instructor->ragas) (3.1.6)\n",
      "Collecting openai>=1.0.0 (from ragas)\n",
      "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pre-commit>=4.3.0 (from instructor->ragas)\n",
      "  Downloading pre_commit-4.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from instructor->ragas) (9.1.2)\n",
      "Collecting ty>=0.0.1a23 (from instructor->ragas)\n",
      "  Downloading ty-0.0.1a28-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from rich->ragas) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from rich->ragas) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from typer->ragas) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer->ragas)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit>=4.3.0->instructor->ragas)\n",
      "  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas) (4.4.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langchain->ragas) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langchain->ragas) (0.4.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langchain->ragas) (2.0.43)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.2.4)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain->ragas) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain->ragas) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain->ragas) (0.24.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langchain-community->ragas) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from langchain-community->ragas) (0.4.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (1.1.0)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_openai (from ragas)\n",
      "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core (from ragas)\n",
      "  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from tiktoken->ragas) (2025.8.29)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from pandas->datasets>=4.0.0->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from pandas->datasets>=4.0.0->ragas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from pandas->datasets>=4.0.0->ragas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=4.0.0->ragas) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /home/user/anaconda3/envs/ji_env/lib/python3.10/site-packages (from scikit-network->ragas) (1.15.3)\n",
      "Downloading ragas-0.3.9-py3-none-any.whl (366 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading instructor-1.13.0-py3-none-any.whl (160 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading pre_commit-4.5.0-py2.py3-none-any.whl (226 kB)\n",
      "Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
      "Downloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
      "Using cached nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading ty-0.0.1a28-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
      "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
      "Downloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
      "Downloading scikit_network-0.33.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: distlib, appdirs, virtualenv, ty, smmap, shellingham, nodeenv, identify, docstring-parser, diskcache, cfgv, scikit-network, pre-commit, gitdb, typer, gitpython, openai, langchain-core, instructor, langchain_openai, ragas\n",
      "\u001b[2K  Attempting uninstall: openai0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/21\u001b[0m [scikit-network]\n",
      "\u001b[2K    Found existing installation: openai 1.107.3â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/21\u001b[0m [scikit-network]\n",
      "\u001b[2K    Uninstalling openai-1.107.3:â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/21\u001b[0m [openai]ork]\n",
      "\u001b[2K      Successfully uninstalled openai-1.107.3[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/21\u001b[0m [openai]\n",
      "\u001b[2K  Attempting uninstall: langchain-core\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/21\u001b[0m [openai]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.76â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/21\u001b[0m [openai]\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.76:[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/21\u001b[0m [openai]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.76mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/21\u001b[0m [openai]\n",
      "\u001b[2K  Attempting uninstall: langchain_openai\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m17/21\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-openai 0.3.33â”â”â”â”â”â”\u001b[0m \u001b[32m17/21\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-openai-0.3.33:[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m17/21\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-openai-0.3.33mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m17/21\u001b[0m [langchain-core]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21/21\u001b[0m [ragas]m20/21\u001b[0m [ragas]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed appdirs-1.4.4 cfgv-3.5.0 diskcache-5.6.3 distlib-0.4.0 docstring-parser-0.17.0 gitdb-4.0.12 gitpython-3.1.45 identify-2.6.15 instructor-1.13.0 langchain-core-0.3.80 langchain_openai-0.3.35 nodeenv-1.9.1 openai-2.8.1 pre-commit-4.5.0 ragas-0.3.9 scikit-network-0.33.5 shellingham-1.5.4 smmap-5.0.2 ty-0.0.1a28 typer-0.20.0 virtualenv-20.35.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65525c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "============================================================\n",
      "ì´ 99ê°œì˜ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ:\n",
      "                                  question  \\\n",
      "0            ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”   \n",
      "1       ì´ë™ì‹ ë¹„ê³„(MSS)ì˜ ì •ì˜ì™€ ë°©ì‹ì— ë”°ë¥¸ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?   \n",
      "2       ê°•ì•„ì¹˜êµì—ì„œ ì•„ì¹˜ë¦¬ë¸Œ(Rib)ë€ ë¬´ì—‡ì´ë©° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?   \n",
      "3                PCTê±°ë”êµì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?   \n",
      "4  í˜„ìˆ˜êµ(Suspension bridge)ë€ ì–´ë–¤ êµëŸ‰ í˜•ì‹ì„ ë§í•˜ë‚˜ìš”?   \n",
      "\n",
      "                                            contexts  \\\n",
      "0  [ì´ì§€ì¹¨ì€ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™(ì´í•˜â€œì•ˆì „ë³´ê±´ê·œì¹™â€ì´ë¼í•œë‹¤) ì œ56ì¡° ì˜ê·œì •(ì‘ì—…...   \n",
      "1  [(6) ì´ë™ëŒ€ì°¨ëŠ”ì¸ì–‘í•˜ì—¬êµê°ë¸Œë¼ì¼“ìƒë¶€ì˜ë ˆì¼ìœ„ì—ì°¨ë¥œì´ë†“ì´ë„ë¡ì„¤ì¹˜ í•˜ê³ ì´ë™ëŒ€ì°¨ê°€ë¶ˆì‹œì—...   \n",
      "2  [(ë‚˜) â€œì£¼íƒ‘(Pylon)â€ì´ë¼í•¨ì€ì‚¬ì¥êµì™€ë§ˆì°¬ê°€ì§€ë¡œì£¼ì¼€ì´ë¸”ì˜í•˜ì¤‘ì„ê¸°ì´ˆì— ì „ë‹¬í•˜ëŠ”ì—­...   \n",
      "3  [(1) ìŠ¬ë¼ì´ë”©íŒ¨ë“œëŠ”ì œì‘ì¥, íš¡ë°©í–¥ê°€ì´ë“œ, êµëŒ€ë°êµê°, ì¶”ì§„ì½”ì—°ê²°ê±°ë”ë“± ì—ë§ëŠ”ì ì •...   \n",
      "4  [(1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤. (ê°€) â€œí˜„ìˆ˜êµ(Suspension...   \n",
      "\n",
      "                                        ground_truth  \n",
      "0  ì´ì§€ì¹¨ì€êµëŸ‰í˜•ì‹ì¤‘ì£¼íƒ‘ì—ê²½ì‚¬ì§€ê²Œì„¤ì¹˜ëœì¼€ì´ë¸”ë¡œêµëŸ‰ì˜ìƒíŒì„ì—°ê²° ì§€ì§€í•˜ëŠ”í˜•ì‹ì¸ì‚¬ì¥êµì˜ì•ˆì „í•œ...  \n",
      "1  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©í•˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œì´ë™ì‹ë¹„ê³„(Mo...  \n",
      "2  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ëœ»ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œê°•ì•„ì¹˜êµâ€ë¼í•¨ì€ì£¼...  \n",
      "3  (1) PCTê±°ë”êµì˜ì£¼ìš”íŠ¹ì§•ì€ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) ì¢…ë‹¨ë°í‰ë©´ì„ í˜•ì—ì œì•½ì„ë°›...  \n",
      "4  (1) ì´ì§€ì¹¨ì—ì„œì‚¬ìš©ë˜ëŠ”ìš©ì–´ì˜ì •ì˜ëŠ”ë‹¤ìŒê³¼ê°™ë‹¤.\\n\\n    (ê°€) â€œí˜„ìˆ˜êµ(Susp...  \n",
      "RAGAS í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "í‰ê°€ ë°ì´í„° ìˆ˜: 99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ff0f446216460b8c52944f4a200ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[106]: TimeoutError()\n",
      "Exception raised in Job[138]: TimeoutError()\n",
      "Exception raised in Job[152]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "============================================================\n",
      "í‰ê°€ ê²°ê³¼:\n",
      "============================================================\n",
      "                                  question  context_precision  context_recall\n",
      "0            ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”           1.000000             1.0\n",
      "1       ì´ë™ì‹ ë¹„ê³„(MSS)ì˜ ì •ì˜ì™€ ë°©ì‹ì— ë”°ë¥¸ ì¢…ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?           1.000000             1.0\n",
      "2       ê°•ì•„ì¹˜êµì—ì„œ ì•„ì¹˜ë¦¬ë¸Œ(Rib)ë€ ë¬´ì—‡ì´ë©° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?           1.000000             1.0\n",
      "3                PCTê±°ë”êµì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?           0.988889             1.0\n",
      "4  í˜„ìˆ˜êµ(Suspension bridge)ë€ ì–´ë–¤ êµëŸ‰ í˜•ì‹ì„ ë§í•˜ë‚˜ìš”?           1.000000             1.0\n",
      "\n",
      "============================================================\n",
      "ì „ì²´ í‰ê·  ì ìˆ˜:\n",
      "============================================================\n",
      "Context Precision í‰ê· : 0.9914\n",
      "Context Recall í‰ê· : 0.8287\n",
      "\n",
      "============================================================\n",
      "Context Precisionì´ ë‚®ì€ ìƒìœ„ 5ê°œ:\n",
      "============================================================\n",
      "                                             question  context_precision  \\\n",
      "34  ë¸”ë¡ì‹ ë³´ê°•í†  ì˜¹ë²½ ì‹œê³µ ì™„ë£Œ í›„ ì˜¹ë²½ ë†’ì´ì— ëŒ€í•œ í—ˆìš© ê¸°ìš¸ê¸°(ìˆ˜ì§ë„) ê¸°ì¤€ì€ ì–¼...           0.645370   \n",
      "63  íƒ€ì›Œí¬ë ˆì¸ ì„¤ì¹˜, ì¡°ë¦½, í•´ì²´ ì‘ì—…ì„ í•˜ëŠ” ê²½ìš° ì‘ì—… ê³„íšì„œì— ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•˜...           0.841226   \n",
      "72  ë¯¸ì¥ê³µì‚¬ ì™„ë£Œ í›„, ê°€ì‹œì„¤ í•´ì²´ ì‘ì—… ì‹œ 2m ì´ìƒ ê³ ì†Œë¶€ìœ„ì—ì„œ ì¶”ë½ ë°©ì§€ë¥¼ ìœ„í•´ ...           0.878263   \n",
      "64  ì´ë™ì‹ í¬ë ˆì¸ ì¸ì–‘ ì‘ì—… ì¤‘, ì•…ì²œí›„ë¡œ ì¸í•´ ì‘ì—…ì„ ì¤‘ì§€í•´ì•¼ í•˜ëŠ” í’ì† ê¸°ì¤€ì€ ì´ˆë‹¹...           0.884354   \n",
      "32  ì‚¬ì§ˆì§€ë°˜(ì í† ì§ˆ ë¯¸í¬í•¨) êµ´ì°© ì‹œ ì•ˆì „ì„ í™•ë³´í•˜ê¸° ìœ„í•´ ì¤€ìˆ˜í•´ì•¼ í•  êµ´ì°©ë©´ì˜ ê¸°ìš¸ê¸°...           0.962654   \n",
      "\n",
      "    context_recall  \n",
      "34        0.333333  \n",
      "63        1.000000  \n",
      "72        0.666667  \n",
      "64        1.000000  \n",
      "32        1.000000  \n",
      "\n",
      "============================================================\n",
      "Context Recallì´ ë‚®ì€ ìƒìœ„ 5ê°œ:\n",
      "============================================================\n",
      "                                             question  context_precision  \\\n",
      "9   I.L.M ê³µë²•ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¶”ì§„ì½”(Launching nose)ì˜ ê¸°ëŠ¥ê³¼ ì„¤ì¹˜ ê¸°ì¤€...                1.0   \n",
      "41  ì½˜í¬ë¦¬íŠ¸ íŒí”„ì˜ íŒŒì´í”„ ë°°ê´€ ì„¤ì¹˜ ì‹œ, ì €ì•• íŒŒì´í”„ì™€ ê³ ì•• íŒŒì´í”„ì˜ ìµœì†Œ ë‘ê»˜ëŠ” ê°...                1.0   \n",
      "49  ìˆ˜ì§ ë³´í˜¸ë§ì„ ì§€ì§€ëŒ€ì— ì„¤ì¹˜í•  ë•Œ ì„¤ì¹˜ ê°„ê²©ì€ ìµœëŒ€ ëª‡ cm ì´í•˜ë¡œ í•˜ê³  í‹ˆìƒˆë‚˜ ì²˜...                1.0   \n",
      "40  ì¹¨ë§¤ ê³µë²•ì˜ ê³µí†µì ì¸ ì•ˆì „ ì¡°ì¹˜ ì‚¬í•­ ì¤‘, ê·¼ë¡œìê°€ í•´ìƒ ì‘ì—… ì¤‘ì§€ ê¸°ì¤€ìœ¼ë¡œ ì•Œì•„ì•¼...                1.0   \n",
      "70  ê±´ì„¤ìš© ë¦¬í”„íŠ¸ ì„¤ì¹˜ ì‹œ, ë§ˆìŠ¤íŠ¸ ì§€ì§€ ê¸°ì¤€ì€ ìµœí•˜ì¸µì€ ëª‡ m ì´ë‚´ì— ì„¤ì¹˜í•˜ê³  ì¤‘ê°„ì¸µ...                1.0   \n",
      "\n",
      "    context_recall  \n",
      "9            0.000  \n",
      "41           0.000  \n",
      "49           0.000  \n",
      "40           0.125  \n",
      "70           0.125  \n",
      "\n",
      "ê²°ê³¼ê°€ 'RAGAS_retriever_evaluation_results(multi).csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import context_precision, context_recall\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "# LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# /home/tmdrb/construction-safety-reporteragent/llm_multidb_retrieval_result.csv' ->  í•´ë‹¹ csv ê¸°ì¤€ \n",
    "def load_and_prepare_data(csv_path):\n",
    "    \"\"\"\n",
    "    CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  RAGAS í‰ê°€ë¥¼ ìœ„í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    \n",
    "    Args:\n",
    "        csv_path: CSV íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    # CSV ë¡œë“œ\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # ì»¬ëŸ¼ëª… ë³€ê²½ (í•„ìš”í•œ ê²½ìš°)\n",
    "    df1 = df[['question', 'retrieval_result', 'chunk']].rename(\n",
    "        columns={\n",
    "            'retrieval_result': 'contexts',\n",
    "            'chunk': 'ground_truth'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # contextsë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë¬¸ìì—´ë¡œ ì €ì¥ë˜ì–´ ìˆëŠ” ê²½ìš°)\n",
    "    if isinstance(df1['contexts'].iloc[0], str):\n",
    "        df1['contexts'] = df1['contexts'].apply(ast.literal_eval)\n",
    "    \n",
    "    return df1\n",
    "\n",
    "\n",
    "def prepare_ragas_dataset(df):\n",
    "    \"\"\"\n",
    "    ë°ì´í„°í”„ë ˆì„ì„ RAGAS Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    \"\"\"\n",
    "    dataset_dict = {\n",
    "        'question': df['question'].tolist(),\n",
    "        'contexts': df['contexts'].tolist(),\n",
    "        'ground_truth': df['ground_truth'].tolist()\n",
    "    }\n",
    "    return Dataset.from_dict(dataset_dict)\n",
    "\n",
    "\n",
    "# 3. RAGAS í‰ê°€ ì‹¤í–‰\n",
    "def evaluate_retriever(df, llm_model):\n",
    "    \"\"\"\n",
    "    Retriever ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê° í–‰ë³„ë¡œ ì ìˆ˜ë¥¼ ë°˜í™˜\n",
    "    \n",
    "    Args:\n",
    "        df: í‰ê°€í•  ë°ì´í„°í”„ë ˆì„ (question, contexts, ground_truth ì»¬ëŸ¼ í•„ìš”)\n",
    "        llm_model: RAGAS í‰ê°€ì— ì‚¬ìš©í•  LLM ëª¨ë¸\n",
    "    \n",
    "    Returns:\n",
    "        ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì— context_precision, context_recall ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dataset ìƒì„±\n",
    "    ragas_dataset = prepare_ragas_dataset(df)\n",
    "    \n",
    "    # RAGAS í‰ê°€ ì‹¤í–‰\n",
    "    print(\"RAGAS í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    print(f\"í‰ê°€ ë°ì´í„° ìˆ˜: {len(ragas_dataset)}\")\n",
    "    \n",
    "    results = evaluate(\n",
    "        dataset=ragas_dataset,\n",
    "        metrics=[\n",
    "            context_precision,  # ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì •ë°€ë„ (ì“¸ëª¨ìˆëŠ” ë¬¸ì„œ ë¹„ìœ¨)\n",
    "            context_recall      # ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì¬í˜„ìœ¨ (í•„ìš”í•œ ì •ë³´ í¬í•¨ ì—¬ë¶€)\n",
    "        ],\n",
    "        llm=llm_model\n",
    "    )\n",
    "    \n",
    "    print(\"í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
    "    results_df = results.to_pandas()\n",
    "    \n",
    "    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì— ì ìˆ˜ ì¶”ê°€\n",
    "    df_with_scores = df.copy()\n",
    "    df_with_scores['context_precision'] = results_df['context_precision']\n",
    "    df_with_scores['context_recall'] = results_df['context_recall']\n",
    "    \n",
    "    return df_with_scores, results\n",
    "\n",
    "\n",
    "def main(csv_path, output_path=None):\n",
    "    \"\"\"\n",
    "    CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  RAGAS í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        csv_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ\n",
    "        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ)\n",
    "    \n",
    "    Returns:\n",
    "        í‰ê°€ê°€ ì™„ë£Œëœ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "    df1 = load_and_prepare_data(csv_path)\n",
    "    \n",
    "    print(f\"ì´ {len(df1)}ê°œì˜ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"\\nì›ë³¸ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "    print(df1.head())\n",
    "    \n",
    "    # í‰ê°€ ì‹¤í–‰\n",
    "    df_evaluated, eval_results = evaluate_retriever(df1, llm)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"í‰ê°€ ê²°ê³¼:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(df_evaluated[['question', 'context_precision', 'context_recall']].head())\n",
    "    \n",
    "    # ì „ì²´ í‰ê·  ì ìˆ˜\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì „ì²´ í‰ê·  ì ìˆ˜:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Context Precision í‰ê· : {df_evaluated['context_precision'].mean():.4f}\")\n",
    "    print(f\"Context Recall í‰ê· : {df_evaluated['context_recall'].mean():.4f}\")\n",
    "    \n",
    "    # ë‚®ì€ ì ìˆ˜ ì¼€ì´ìŠ¤ í™•ì¸\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Context Precisionì´ ë‚®ì€ ìƒìœ„ 5ê°œ:\")\n",
    "    print(\"=\" * 60)\n",
    "    low_precision = df_evaluated.nsmallest(5, 'context_precision')[\n",
    "        ['question', 'context_precision', 'context_recall']\n",
    "    ]\n",
    "    print(low_precision)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Context Recallì´ ë‚®ì€ ìƒìœ„ 5ê°œ:\")\n",
    "    print(\"=\" * 60)\n",
    "    low_recall = df_evaluated.nsmallest(5, 'context_recall')[\n",
    "        ['question', 'context_precision', 'context_recall']\n",
    "    ]\n",
    "    print(low_recall)\n",
    "    \n",
    "    if output_path:\n",
    "        df_evaluated.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nê²°ê³¼ê°€ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return df_evaluated\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    CSV_PATH = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/evaluate_RAG/llm_multidb_retrieval_result.csv\"  \n",
    "    OUTPUT_PATH = \"RAGAS_retriever_evaluation_results(multi).csv\"  \n",
    "    \n",
    "    df_result = main(CSV_PATH, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92d596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a47246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiseok",
   "language": "python",
   "name": "ji_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
