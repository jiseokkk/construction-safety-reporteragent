import os
import json
import pickle
from tqdm import tqdm
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.schema import Document

# ===== 1ï¸âƒ£ ê²½ë¡œ ì„¤ì • =====
base_dir = "/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent"
chunk_dir = os.path.join(base_dir, "data/chunks")  # âœ… ìƒëŒ€ê²½ë¡œë¡œ ìˆ˜ì •
save_dir = os.path.join(base_dir, "DB")            # âœ… ì €ì¥ ê²½ë¡œ ìˆ˜ì •

# ===== 2ï¸âƒ£ Qwen Embedding API ì„¤ì • =====
embedder_model_name = "Qwen/Qwen3-Embedding-4B"
embedder_base_url = "http://211.47.56.71:15653/v1"
embedder_api_key = "token-abc123"

embedding_model = OpenAIEmbeddings(
    model=embedder_model_name,
    base_url=embedder_base_url,
    api_key=embedder_api_key
)

# ===== 3ï¸âƒ£ chunk íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° =====
chunk_json_path = os.path.join(chunk_dir, "chunks.json")
chunk_pkl_path = os.path.join(chunk_dir, "chunks.pkl")

chunks = []

if os.path.exists(chunk_json_path):
    print(f"ğŸ“‚ JSON íŒŒì¼ì—ì„œ ì²­í¬ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {chunk_json_path}")
    with open(chunk_json_path, "r", encoding="utf-8") as f:
        chunks = json.load(f)

elif os.path.exists(chunk_pkl_path):
    print(f"ğŸ“‚ PKL íŒŒì¼ì—ì„œ ì²­í¬ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {chunk_pkl_path}")
    with open(chunk_pkl_path, "rb") as f:
        chunks = pickle.load(f)
else:
    raise FileNotFoundError("âŒ chunk.json ë˜ëŠ” chunk.pkl íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

print(f"âœ… ì´ ë¡œë“œëœ ì²­í¬ ìˆ˜: {len(chunks)}")

# ===== 4ï¸âƒ£ LangChain ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ =====
docs = []
for c in tqdm(chunks, desc="ğŸ§© Document ë³€í™˜ ì¤‘"):
    # ì˜ˆì‹œ êµ¬ì¡°:
    # {"content": "...", "file": "ê±´ì„¤ê³µì‚¬ì˜ ê³ ì†Œì‘ì—…ëŒ€ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md", "section": "5. ê³ ì†Œì‘ì—…ëŒ€ì˜ì•ˆì „ì¥ì¹˜"}
    text = c.get("content") or c.get("page_content") or ""

    # âœ… íŒŒì¼ëª…/ì¶œì²˜, ì„¹ì…˜ëª… ëª¨ë‘ ì•ˆì „í•˜ê²Œ ë³‘í•©
    meta = {
        "source": c.get("source") or c.get("file") or c.get("filename") or "unknown",
        "section": c.get("section") or c.get("heading") or "ë³¸ë¬¸"
    }

    docs.append(Document(page_content=text, metadata=meta))

print(f"âœ… LangChain ë¬¸ì„œ ê°œì²´ë¡œ ë³€í™˜ ì™„ë£Œ: {len(docs)}ê°œ")

# ===== 5ï¸âƒ£ FAISS ë²¡í„° DB ìƒì„± =====
print("ğŸ§  ì„ë² ë”© ë° ë²¡í„° ìƒì„± ì¤‘... (Qwen3-Embedding-4B)")
db = FAISS.from_documents(docs, embedding_model)

# ===== 6ï¸âƒ£ DB ì €ì¥ =====
os.makedirs(save_dir, exist_ok=True)
db.save_local(save_dir)

print(f"\nâœ… RAG ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ!")
print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {save_dir}")
print(f"ğŸ§© ì´ ì²­í¬ ìˆ˜: {len(docs)}")

# ===== 7ï¸âƒ£ í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ =====
query = "ì´ë™ì‹ì‘ì—…ëŒ€ì°¨ ì•ˆì „ì¡°ì¹˜"
results = db.similarity_search(query, k=3)

print("\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼:")
for r in results:
    print(f"\n[íŒŒì¼] {r.metadata.get('source', '')} | [ì„¹ì…˜] {r.metadata.get('section', '')}")
    print(r.page_content[:300], "...\n")
