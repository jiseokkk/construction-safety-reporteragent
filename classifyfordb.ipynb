{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8ea405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ì¥ ì™„ë£Œ: /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/data_md/all_md_titles.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# md íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë”\n",
    "md_dir = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/data_md\"\n",
    "\n",
    "# ì €ì¥í•  íŒŒì¼ ê²½ë¡œ\n",
    "output_path = os.path.join(md_dir, \"all_md_titles.md\")\n",
    "\n",
    "titles = []\n",
    "\n",
    "# md íŒŒì¼ë“¤ ìˆœíšŒ\n",
    "for fname in sorted(os.listdir(md_dir)):\n",
    "    if fname.lower().endswith(\".md\"):\n",
    "        path = os.path.join(md_dir, fname)\n",
    "        \n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ Markdown ì œëª©(#) ì°¾ê¸°\n",
    "        title = None\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"#\"):\n",
    "                title = line.strip().lstrip(\"#\").strip()\n",
    "                break\n",
    "        \n",
    "        # ì œëª© ì €ì¥\n",
    "        if title:\n",
    "            titles.append(title)\n",
    "\n",
    "# ChatGPTì—ê²Œ ë¶™ì—¬ë„£ê¸° ì¢‹ì€ Markdown êµ¬ì¡° ë§Œë“¤ê¸°\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# ğŸ“„ Markdown íŒŒì¼ ì œëª© ëª©ë¡\\n\\n\")\n",
    "    for i, t in enumerate(titles, 1):\n",
    "        f.write(f\"{i}. {t}\\n\")\n",
    "\n",
    "print(\"ì €ì¥ ì™„ë£Œ:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a6f1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë¯¸ë¶„ë¥˜] í•´ì²´ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ë°€íê³µê°„ì˜ ë°©ìˆ˜ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[ë¯¸ë¶„ë¥˜] ì² ê³¨ê³µì‚¬ ë¬´ì§€ë³´ ê±°í‘¸ì§‘ë™ë°”ë¦¬(ë°í¬í”Œë ˆì´íŠ¸ ê³µë²•)ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ë¯¸ì¥ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[ë¯¸ë¶„ë¥˜] ì² íƒ‘ê³µì‚¬ ì•ˆì „ë³´ê±´ê¸°ìˆ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[ë¯¸ë¶„ë¥˜] ê±´ì„¤ê³µì‚¬ì˜ ê³ ì†Œì‘ì—…ëŒ€ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] íƒ€ì›Œí¬ë ˆì¸ ì„¤ì¹˜, ì¡°ë¦½, í•´ì²´ ì‘ì—…ê³„íšì„œ ì‘ì„±ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(Soil Nailing ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[ë¯¸ë¶„ë¥˜] ì¡°ì ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] í„°ë„ê³µì‚¬(NTRê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] êµëŸ‰ê³µì‚¬ì˜ ì´ë™ì‹ ë¹„ê³„ê³µë²•(MSS) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] ì½˜í¬ë¦¬íŠ¸ê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(ì§€í•˜ì—°ì†ë²½) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ê°•ì•„ì¹˜êµ(ë²¤íŠ¸ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] ìš°ë¬¼í†µê¸°ì´ˆ ì•ˆì „ë³´ê±´ ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ê°€ì„¤êµ¬ì¡°ë¬¼ì˜ ì„¤ê³„ë³€ê²½ ìš”ì²­ ë‚´ìš©, ì ˆì°¨ ë“±ì— ê´€í•œ ì‘ì„±ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[ë¯¸ë¶„ë¥˜] ì•¼ê°„ ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ì‹œíŠ¸(Sheet)ë°©ìˆ˜ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(ê°•ë„ë§ëš, Sheet Pile)ì˜ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[ë¯¸ë¶„ë¥˜] ê°±í¼(Gang form) ì œì‘ ë° ì‚¬ìš©ì•ˆì „ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[ë¯¸ë¶„ë¥˜] ì¤‘ì†Œê·œëª¨ ê±´ì„¤ì—…ì²´ ë³¸ì‚¬ì˜ ì•ˆì „ë³´ê±´ê´€ë¦¬ì— ê´€í•œ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ë‚™í•˜ë¬¼ ë°©í˜¸ì„ ë°˜ ì„¤ì¹˜ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(Earth Anchor ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í„°ë„ê³µì‚¬(í”„ë¡ íŠ¸ì­í‚¹) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(ì—„ì§€ë§ëš ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ê±´ì„¤ê³µì‚¬ êµ´ì°©ë©´ ì•ˆì „ê¸°ìš¸ê¸° ê¸°ì¤€ì— ê´€í•œ ê¸°ìˆ ì§€ì¹¨.md â†’ 02_earth\n",
      "[ë¯¸ë¶„ë¥˜] ì‹œìŠ¤í…œí¼(RCSí¼,ACSí¼ ì¤‘ì‹¬) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ê±´ì¶•ë¬¼ì˜ ì„ê³µì‚¬(ë‚´ì™¸ì¥) ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ì´ë™ì‹ í¬ë ˆì¸ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] PCTê±°ë” êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] ê°•ê´€ë¹„ê³„ ì•ˆì „ì‘ì—…ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[ë¯¸ë¶„ë¥˜] ê±´ì„¤í˜„ì¥ ìš©ì ‘ìš©ë‹¨ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[ë¯¸ë¶„ë¥˜] ì¡°ê²½ê³µì‚¬(ìˆ˜ëª©ì‹ì¬ì‘ì—…) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ìˆ˜ì§ë³´í˜¸ë§ ì„¤ì¹˜ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ëƒ‰ë™ëƒ‰ì¥ ë¬¼ë¥˜ì°½ê³  ë‹¨ì—´ê³µì‚¬ í™”ì¬ì˜ˆë°© ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] í˜„ìˆ˜êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] í•­íƒ€ê¸°, í•­ë°œê¸° ì‚¬ìš© ì‘ì—…ê³„íšì„œ ì‘ì„±ì§€ì¹¨.md â†’ 05_crane\n",
      "[ë¯¸ë¶„ë¥˜] ìˆ˜ìƒ ë°”ì§€(Barge)ì„  ì´ìš© ê±´ì„¤ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] í„°ë„ê³µì‚¬(Shield-T.B.Mê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] ì‘ì—…ë°œíŒ ì„¤ì¹˜ ë° ì‚¬ìš©ì•ˆì „ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] êµëŸ‰ ìŠ¬ë˜ë¸Œê±°í‘¸ì§‘ í•´ì²´ìš© ì‘ì—…ëŒ€ì°¨ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(ë ì¥ê¸´ì¥ê³µë²•, Prestressed Wale Method) ì•ˆì „ë³´ê±´ ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[ë¯¸ë¶„ë¥˜] í™”í•™í”ŒëœíŠ¸ ê°œë³´ìˆ˜ ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ê±´ì„¤í˜„ì¥ì˜ ì¤‘ëŸ‰ë¬¼ ì·¨ê¸‰ ì‘ì—…ê³„íšì„œ(ì´ë™ì‹í¬ë ˆì¸) ì‘ì„±ì§€ì¹¨.md â†’ 05_crane\n",
      "[ë¯¸ë¶„ë¥˜] ì´ˆê³ ì¸µ ê±´ì¶•ë¬¼ê³µì‚¬(í™”ì¬ì˜ˆë°©) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[ë¯¸ë¶„ë¥˜] ê³¤ëŒë¼(Gondola) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] êµëŸ‰ê³µì‚¬(ë¼ë©˜êµ) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] ë°œíŒŒê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] ì§€í•˜ë§¤ì„¤ë¬¼ êµ´ì°©ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ë‚´ì¥ê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ì´ë™ì‹ ë¹„ê³„ ì„¤ì¹˜ ë° ì‚¬ìš©ì•ˆì „ ê¸°ìˆ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[ë¯¸ë¶„ë¥˜] ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ ì„¤ê³„ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] í˜„ìˆ˜êµ ì£¼íƒ‘ì‹œê³µ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] êµ´ì°©ê³µì‚¬ ê³„ì¸¡ê´€ë¦¬ ê¸°ìˆ ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ì˜¹ë²½(ì½˜í¬ë¦¬íŠ¸ ì˜¹ë²½)ê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[ë¯¸ë¶„ë¥˜] ìŠ¬ë¦½í¼(Slip form) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[ë¯¸ë¶„ë¥˜] ì¤‘ì†Œê·œëª¨ ê´€ë¡œê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[ë¯¸ë¶„ë¥˜] ì•ˆì „ëŒ€ ì‚¬ìš©ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ë¤í”„íŠ¸ëŸ­ ë° í™”ë¬¼ìë™ì°¨ ì•ˆì „ì‘ì—…ì§€ì¹¨.md â†’ 05_crane\n",
      "[ë¯¸ë¶„ë¥˜] ì´ˆê³ ì¸µ ê±´ì¶•ë¬¼ê³µì‚¬(ì¼ë°˜ì‚¬í•­) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ê¸ˆì† ì»¤íŠ¼ì›”(Curtain wall) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ì‘ì—…ì˜ìí˜• ë‹¬ë¹„ê³„ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] íŠ¸ëŸ­ íƒ‘ì¬í˜• í¬ë ˆì¸(Cago crane) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] ê°€ê³µì†¡ì „ì„ ë¡œ ì² íƒ‘ ì‹¬í˜•ê¸°ì´ˆê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í™ë§‰ì´ê³µì‚¬ (SCW ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ìˆ˜ì§í˜• ì¶”ë½ë°©ë§ ì„¤ì¹˜ ê¸°ìˆ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ê°€ì„¤ê³„ë‹¨ ì„¤ì¹˜ ë° ì‚¬ìš© ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ì†Œê·œëª¨ ì² ê·¼ì½˜í¬ë¦¬íŠ¸ êµëŸ‰ê³µì‚¬ ê±°í‘¸ì§‘ ë™ë°”ë¦¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[ë¯¸ë¶„ë¥˜] all_md_titles.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] êµ´ì°©ê¸° ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[ë¯¸ë¶„ë¥˜] íŒŒì´í”„ ì„œí¬íŠ¸ ë™ë°”ë¦¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ê¸°ì„± ì½˜í¬ë¦¬íŠ¸ íŒŒì¼ í•­íƒ€ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[ë¯¸ë¶„ë¥˜] ì² ê³¨ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(C.I.Pê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ì‹œìŠ¤í…œ ë¹„ê³„ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] I.L.M êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] íŠ¸ëŸ¬ìŠ¤ê±°ë” êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] í•´ìƒ RCD í˜„ì¥íƒ€ì„¤ ë§ëšê³µì‚¬(í˜„ìˆ˜êµ, ì‚¬ì¥êµ) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] êµ´ì°©ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[ë¯¸ë¶„ë¥˜] ì·¨ì•½ì‹œê¸° ê±´ì„¤í˜„ì¥ ì•ˆì „ì‘ì—…ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ê±´ì„¤ê¸°ê³„ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 05_crane\n",
      "[ë¯¸ë¶„ë¥˜] ê´€ë¡œë§¤ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] í„°ë„ê³µì‚¬(ì¹¨ë§¤ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] ë¸”ë¡ì‹ ë³´ê°•í†  ì˜¹ë²½ ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[ë¯¸ë¶„ë¥˜] ê´€ë¡œë§¤ì„¤ê³µì‚¬(ìœ ì••ì‹ ì¶”ì§„ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] ë‚™í•˜ë¬¼ ë°©ì§€ë§ ì„¤ì¹˜ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] íƒ€ì¼(Tile) ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] êµëŸ‰ê³µì‚¬(P.S.Mê³µë²•) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[ë¯¸ë¶„ë¥˜] ì¶”ë½ë°©í˜¸ë§ ì„¤ì¹˜ ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] í”„ë¦¬ìºìŠ¤íŠ¸ ì½˜í¬ë¦¬íŠ¸ ê±´ì¶•êµ¬ì¡°ë¬¼ ì¡°ë¦½ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[OK] í”„ë¦¬ìŠ¤íŠ¸ë ˆìŠ¤íŠ¸ ì½˜í¬ë¦¬íŠ¸(PSC) êµëŸ‰ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[ë¯¸ë¶„ë¥˜] ê±´ì„¤ê³µì‚¬ ëŒê´€ì‘ì—… ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] F.C.M êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] íƒ‘ë‹¤ìš´(Top down) ê³µë²• ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] ë‹¨ìˆœ ìŠ¬ë˜ë¸Œ ì½˜í¬ë¦¬íŠ¸ íƒ€ì„¤ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[OK] ì•„ìŠ¤íŒ”íŠ¸ì½˜í¬ë¦¬íŠ¸ í¬ì¥ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[ë¯¸ë¶„ë¥˜] ì‹œìŠ¤í…œ ë™ë°”ë¦¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\n",
      "[OK] í„°ë„ê³µì‚¬(NATMê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] ê²½ëŸ‰ì² ê³¨ ì²œì¥ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "\n",
      "ğŸ‰ DB íŒŒì¼ ë¶„ë¥˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# md íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬\n",
    "md_dir = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/data_md\"\n",
    "\n",
    "# DB í´ë” ê¸°ë³¸ê²½ë¡œ\n",
    "db_root = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB\"\n",
    "\n",
    "# ====== 7ê°œ DB ë¶„ë¥˜ ê¸°ì¤€ ======\n",
    "DB_RULES = {\n",
    "    \"01_bridge\": [\n",
    "        \"êµëŸ‰\", \"ê±°ë”\", \"ì•„ì¹˜êµ\", \"ì‚¬ì¥êµ\", \"í˜„ìˆ˜êµ\", \"PSM\", \"RCD\", \"íŠ¸ëŸ¬ìŠ¤\", \"MSS\", \"ë¼ë©˜êµ\"\n",
    "    ],\n",
    "    \"02_earth\": [\n",
    "        \"í™ë§‰ì´\", \"êµ´ì°©\", \"CIP\", \"SCW\", \"Earth Anchor\", \"Soil Nailing\",\n",
    "        \"Sheet Pile\", \"ì—„ì§€ë§ëš\", \"ì—°ì†ë²½\", \"ì˜¹ë²½\", \"ë³´ê°•í† \", \"ê¸°ì´ˆ\"\n",
    "    ],\n",
    "    \"03_tunnel\": [\n",
    "        \"í„°ë„\", \"NATM\", \"NTR\", \"TBM\", \"Shield\", \"ì¹¨ë§¤ê³µë²•\", \"ë°œíŒŒ\", \"íƒ‘ë‹¤ìš´\"\n",
    "    ],\n",
    "    \"04_scaffold\": [\n",
    "        \"ë¹„ê³„\", \"ê°€ì„¤\", \"ì‘ì—…ë°œíŒ\", \"ë°©ì§€ë§\", \"ë°©í˜¸ì„ ë°˜\", \"ë³´í˜¸ë§\",\n",
    "        \"ë‹¬ë¹„ê³„\", \"ìˆ˜ì§ë³´í˜¸ë§\", \"ì¶”ë½ë°©ë§\", \"ê°€ì„¤ê³„ë‹¨\"\n",
    "    ],\n",
    "    \"05_crane\": [\n",
    "        \"í¬ë ˆì¸\", \"ì–‘ì¤‘\", \"ê±´ì„¤ê¸°ê³„\", \"ì¤‘ëŸ‰ë¬¼\", \"íƒ€ì›Œí¬ë ˆì¸\",\n",
    "        \"í•­íƒ€ê¸°\", \"í•­ë°œê¸°\", \"ë¤í”„íŠ¸ëŸ­\", \"í™”ë¬¼ìë™ì°¨\", \"ë°”ì§€ì„ \"\n",
    "    ],\n",
    "    \"06_finishing\": [\n",
    "        \"ì„ê³µì‚¬\", \"ì»¤íŠ¼ì›”\", \"ë‚´ì¥\", \"ë¯¸ì¥\", \"íƒ€ì¼\", \"ë‹¨ì—´\", \"ë°©ìˆ˜\", \"ì²œì¥\"\n",
    "    ],\n",
    "    \"07_concrete\": [\n",
    "        \"ì½˜í¬ë¦¬íŠ¸\", \"ìŠ¬ë˜ë¸Œ\", \"íŒŒì¼í•­íƒ€\", \"í”„ë¦¬ìºìŠ¤íŠ¸\", \"PSC\", \"PC\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# ====== DB í´ë” ìƒì„± ======\n",
    "os.makedirs(db_root, exist_ok=True)\n",
    "for db_name in DB_RULES.keys():\n",
    "    os.makedirs(os.path.join(db_root, db_name), exist_ok=True)\n",
    "\n",
    "# ====== íŒŒì¼ ë¶„ë¥˜ í•¨ìˆ˜ ======\n",
    "def classify_md(title):\n",
    "    for db_name, keywords in DB_RULES.items():\n",
    "        for kw in keywords:\n",
    "            if kw in title:\n",
    "                return db_name\n",
    "    return None  # ë¯¸ë¶„ë¥˜\n",
    "\n",
    "# ====== md íŒŒì¼ ì½ê³  ë¶„ë¥˜ í›„ ì´ë™ ======\n",
    "for fname in os.listdir(md_dir):\n",
    "    if not fname.endswith(\".md\"):\n",
    "        continue\n",
    "\n",
    "    src_path = os.path.join(md_dir, fname)\n",
    "\n",
    "    with open(src_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        first_line = f.readline().strip()\n",
    "\n",
    "    # ì œëª© ì •ì œ\n",
    "    title = first_line.lstrip(\"# \").strip()\n",
    "\n",
    "    db_category = classify_md(title)\n",
    "\n",
    "    if db_category is None:\n",
    "        print(f\"[ë¯¸ë¶„ë¥˜] {fname} â†’ ë¶„ë¥˜ ê·œì¹™ì— ë§ì§€ ì•ŠìŒ\")\n",
    "        continue\n",
    "\n",
    "    dst_path = os.path.join(db_root, db_category, fname)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "    print(f\"[OK] {fname} â†’ {db_category}\")\n",
    "\n",
    "print(\"\\nğŸ‰ DB íŒŒì¼ ë¶„ë¥˜ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03db70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ğŸ“Œ MD íŒŒì¼ ë¶„ë¥˜ ê²€ì¦ ê²°ê³¼ =====\n",
      "\n",
      "ğŸ“„ ì›ë³¸ md íŒŒì¼ ê°œìˆ˜: 100\n",
      "ğŸ“ DBì— ë¶„ë¥˜ëœ md íŒŒì¼ ê°œìˆ˜: 71\n",
      "\n",
      "âŒ ëˆ„ë½ëœ md íŒŒì¼:\n",
      "  - all_md_titles.md\n",
      "  - ê°±í¼(Gang form) ì œì‘ ë° ì‚¬ìš©ì•ˆì „ ì§€ì¹¨.md\n",
      "  - ê±´ì„¤ê³µì‚¬ ëŒê´€ì‘ì—… ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md\n",
      "  - ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ ì„¤ê³„ ì§€ì¹¨.md\n",
      "  - ê±´ì„¤ê³µì‚¬ì˜ ê³ ì†Œì‘ì—…ëŒ€ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md\n",
      "  - ê±´ì„¤í˜„ì¥ ìš©ì ‘ìš©ë‹¨ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md\n",
      "  - ê³¤ëŒë¼(Gondola) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md\n",
      "  - ê´€ë¡œë§¤ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md\n",
      "  - ê´€ë¡œë§¤ì„¤ê³µì‚¬(ìœ ì••ì‹ ì¶”ì§„ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md\n",
      "  - ìˆ˜ìƒ ë°”ì§€(Barge)ì„  ì´ìš© ê±´ì„¤ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md\n",
      "  - ìŠ¬ë¦½í¼(Slip form) ì•ˆì „ì‘ì—… ì§€ì¹¨.md\n",
      "  - ì‹œìŠ¤í…œ ë™ë°”ë¦¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md\n",
      "  - ì‹œìŠ¤í…œí¼(RCSí¼,ACSí¼ ì¤‘ì‹¬) ì•ˆì „ì‘ì—… ì§€ì¹¨.md\n",
      "  - ì•ˆì „ëŒ€ ì‚¬ìš©ì§€ì¹¨.md\n",
      "  - ì•¼ê°„ ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md\n",
      "  - ì¡°ê²½ê³µì‚¬(ìˆ˜ëª©ì‹ì¬ì‘ì—…) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md\n",
      "  - ì¡°ì ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md\n",
      "  - ì¤‘ì†Œê·œëª¨ ê±´ì„¤ì—…ì²´ ë³¸ì‚¬ì˜ ì•ˆì „ë³´ê±´ê´€ë¦¬ì— ê´€í•œ ì§€ì¹¨.md\n",
      "  - ì¤‘ì†Œê·œëª¨ ê´€ë¡œê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md\n",
      "  - ì² ê³¨ê³µì‚¬ ë¬´ì§€ë³´ ê±°í‘¸ì§‘ë™ë°”ë¦¬(ë°í¬í”Œë ˆì´íŠ¸ ê³µë²•)ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md\n",
      "  - ì² ê³¨ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md\n",
      "  - ì² íƒ‘ê³µì‚¬ ì•ˆì „ë³´ê±´ê¸°ìˆ ì§€ì¹¨.md\n",
      "  - ì´ˆê³ ì¸µ ê±´ì¶•ë¬¼ê³µì‚¬(ì¼ë°˜ì‚¬í•­) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md\n",
      "  - ì´ˆê³ ì¸µ ê±´ì¶•ë¬¼ê³µì‚¬(í™”ì¬ì˜ˆë°©) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md\n",
      "  - ì¶”ë½ë°©í˜¸ë§ ì„¤ì¹˜ ì§€ì¹¨.md\n",
      "  - ì·¨ì•½ì‹œê¸° ê±´ì„¤í˜„ì¥ ì•ˆì „ì‘ì—…ì§€ì¹¨.md\n",
      "  - íŒŒì´í”„ ì„œí¬íŠ¸ ë™ë°”ë¦¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md\n",
      "  - í•´ì²´ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md\n",
      "  - í™”í•™í”ŒëœíŠ¸ ê°œë³´ìˆ˜ ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md\n",
      "\n",
      "â­• DB í´ë”ì—ë§Œ ì¡´ì¬í•˜ëŠ” ì˜ì‹¬ íŒŒì¼ ì—†ìŒ\n",
      "\n",
      "â­• ì¤‘ë³µ ë¶„ë¥˜ëœ íŒŒì¼ ì—†ìŒ\n",
      "\n",
      "===== ì™„ë£Œ =====\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "md_dir = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/data_md\"\n",
    "db_root = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB\"\n",
    "\n",
    "# Step 1. ì›ë³¸ md íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘\n",
    "original_files = sorted([f for f in os.listdir(md_dir) if f.endswith(\".md\")])\n",
    "\n",
    "# Step 2. ëª¨ë“  DB í´ë”ì—ì„œ íŒŒì¼ ìˆ˜ì§‘\n",
    "db_files = []\n",
    "db_map = {}  # íŒŒì¼ â†’ DB í´ë”\n",
    "\n",
    "for db_name in sorted(os.listdir(db_root)):\n",
    "    db_path = os.path.join(db_root, db_name)\n",
    "    if not os.path.isdir(db_path):\n",
    "        continue\n",
    "    for f in os.listdir(db_path):\n",
    "        if f.endswith(\".md\"):\n",
    "            db_files.append(f)\n",
    "            db_map[f] = db_name\n",
    "\n",
    "# Step 3. ë¹„êµ\n",
    "original_set = set(original_files)\n",
    "db_set = set(db_files)\n",
    "\n",
    "missing = original_set - db_set       # ëˆ„ë½ëœ íŒŒì¼\n",
    "extra = db_set - original_set         # ì´ìƒí•˜ê²Œ DBì—ë§Œ ì¡´ì¬í•˜ëŠ” íŒŒì¼\n",
    "duplicates = [f for f in db_files if db_files.count(f) > 1]\n",
    "\n",
    "print(\"===== ğŸ“Œ MD íŒŒì¼ ë¶„ë¥˜ ê²€ì¦ ê²°ê³¼ =====\\n\")\n",
    "print(f\"ğŸ“„ ì›ë³¸ md íŒŒì¼ ê°œìˆ˜: {len(original_files)}\")\n",
    "print(f\"ğŸ“ DBì— ë¶„ë¥˜ëœ md íŒŒì¼ ê°œìˆ˜: {len(db_files)}\\n\")\n",
    "\n",
    "# ëˆ„ë½ íŒŒì¼\n",
    "if missing:\n",
    "    print(\"âŒ ëˆ„ë½ëœ md íŒŒì¼:\")\n",
    "    for m in sorted(missing):\n",
    "        print(\"  -\", m)\n",
    "else:\n",
    "    print(\"â­• ëˆ„ë½ëœ íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ì´ìƒ(ë¶ˆí•„ìš”í•˜ê²Œ DBì—ë§Œ ìˆëŠ” íŒŒì¼)\n",
    "if extra:\n",
    "    print(\"âš ï¸ DB í´ë”ì—ë§Œ ì¡´ì¬í•˜ëŠ” ì˜ì‹¬ íŒŒì¼:\")\n",
    "    for e in sorted(extra):\n",
    "        print(\"  -\", e)\n",
    "else:\n",
    "    print(\"â­• DB í´ë”ì—ë§Œ ì¡´ì¬í•˜ëŠ” ì˜ì‹¬ íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ì¤‘ë³µ íŒŒì¼ (ë‘ DBì— ë“¤ì–´ê°€ ìˆëŠ” ê²½ìš°)\n",
    "if duplicates:\n",
    "    print(\"âš ï¸ ì¤‘ë³µ ë¶„ë¥˜ëœ íŒŒì¼:\")\n",
    "    seen = set()\n",
    "    for d in duplicates:\n",
    "        if d not in seen:\n",
    "            print(f\"  - {d} (DB: {db_map.get(d)})\")\n",
    "            seen.add(d)\n",
    "else:\n",
    "    print(\"â­• ì¤‘ë³µ ë¶„ë¥˜ëœ íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "print(\"\\n===== ì™„ë£Œ =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac79154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Jupyter ì¶œë ¥ ì œí•œ í•´ì œ\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "\n",
    "# Python ê¸°ë³¸ ì¶œë ¥ ì œí•œë„ í•´ì œ\n",
    "sys.setrecursionlimit(1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6eb4f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ë¯¸ë¶„ë¥˜ ëª©ë¡ ì €ì¥ ì™„ë£Œ!\n",
      "ì €ì¥ ìœ„ì¹˜ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/unclassified_titles.txt\n",
      "ì´ 28ê°œ íŒŒì¼ ë¯¸ë¶„ë¥˜ë¨\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# md íŒŒì¼ ìœ„ì¹˜\n",
    "md_dir = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/data_md\"\n",
    "\n",
    "# DB ë¶„ë¥˜ ê·œì¹™ (ê¸°ì¡´)\n",
    "DB_RULES = {\n",
    "    \"01_bridge\": [\"êµëŸ‰\", \"ê±°ë”\", \"ì•„ì¹˜êµ\", \"ì‚¬ì¥êµ\", \"í˜„ìˆ˜êµ\", \"PSM\", \"íŠ¸ëŸ¬ìŠ¤\", \"RCD\", \"ë¼ë©˜\"],\n",
    "    \"02_earth\": [\"í™ë§‰ì´\", \"êµ´ì°©\", \"ì§€í•˜ë§¤ì„¤\", \"SCW\", \"CIP\", \"Earth\", \"Nailing\", \"Sheet\", \"ì˜¹ë²½\", \"ë³´ê°•í† \", \"ê¸°ì´ˆ\"],\n",
    "    \"03_tunnel\": [\"í„°ë„\", \"NATM\", \"NTR\", \"TBM\", \"Shield\", \"ì¹¨ë§¤\", \"ë°œíŒŒ\", \"í”„ë¡ íŠ¸ì­í‚¹\"],\n",
    "    \"04_scaffold\": [\"ë¹„ê³„\", \"ê°€ì„¤\", \"ì‘ì—…ë°œíŒ\", \"ë°©í˜¸\", \"ë‚™í•˜ë¬¼\", \"ì¶”ë½\", \"ë³´í˜¸ë§\", \"ë‹¬ë¹„ê³„\", \"ê°€ì„¤ê³„ë‹¨\"],\n",
    "    \"05_crane\": [\"í¬ë ˆì¸\", \"ì–‘ì¤‘\", \"ê±´ì„¤ê¸°ê³„\", \"ì¤‘ëŸ‰ë¬¼\", \"íƒ€ì›Œí¬ë ˆì¸\", \"í•­íƒ€ê¸°\", \"ë¤í”„\", \"íŠ¸ëŸ­\", \"ë°”ì§€ì„ \"],\n",
    "    \"06_finishing\": [\"ì„ê³µì‚¬\", \"ì»¤íŠ¼ì›”\", \"ë‚´ì¥\", \"ë¯¸ì¥\", \"íƒ€ì¼\", \"ë‹¨ì—´\", \"ë°©ìˆ˜\", \"ì²œì¥\"],\n",
    "    \"07_concrete\": [\"ì½˜í¬ë¦¬íŠ¸\", \"ìŠ¬ë˜ë¸Œ\", \"íŒŒì¼\", \"í”„ë¦¬ìºìŠ¤íŠ¸\", \"PSC\", \"PC\"],\n",
    "}\n",
    "\n",
    "def classify(title):\n",
    "    for db_name, keywords in DB_RULES.items():\n",
    "        for kw in keywords:\n",
    "            if kw in title:\n",
    "                return db_name\n",
    "    return None\n",
    "\n",
    "unclassified = []\n",
    "\n",
    "for fname in sorted(os.listdir(md_dir)):\n",
    "    if fname.endswith(\".md\"):\n",
    "        with open(os.path.join(md_dir, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            first_line = f.readline().strip()\n",
    "            title = first_line.lstrip(\"# \").strip()\n",
    "        \n",
    "        category = classify(title)\n",
    "        if category is None:\n",
    "            unclassified.append((fname, title))\n",
    "\n",
    "# ì €ì¥ ê²½ë¡œ\n",
    "output_file = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/unclassified_titles.txt\"\n",
    "\n",
    "# íŒŒì¼ì— ì €ì¥\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for fname, title in unclassified:\n",
    "        f.write(f\"{fname} : {title}\\n\")\n",
    "\n",
    "print(\"ğŸ“„ ë¯¸ë¶„ë¥˜ ëª©ë¡ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(\"ì €ì¥ ìœ„ì¹˜ â†’\", output_file)\n",
    "print(f\"ì´ {len(unclassified)}ê°œ íŒŒì¼ ë¯¸ë¶„ë¥˜ë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66295a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] F.C.M êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] I.L.M êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] PCTê±°ë” êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] ê°€ê³µì†¡ì „ì„ ë¡œ ì² íƒ‘ ì‹¬í˜•ê¸°ì´ˆê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ê°€ì„¤ê³„ë‹¨ ì„¤ì¹˜ ë° ì‚¬ìš© ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ê°€ì„¤êµ¬ì¡°ë¬¼ì˜ ì„¤ê³„ë³€ê²½ ìš”ì²­ ë‚´ìš©, ì ˆì°¨ ë“±ì— ê´€í•œ ì‘ì„±ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ê°•ê´€ë¹„ê³„ ì•ˆì „ì‘ì—…ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ê°•ì•„ì¹˜êµ(ë²¤íŠ¸ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] ê°±í¼(Gang form) ì œì‘ ë° ì‚¬ìš©ì•ˆì „ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ê±´ì„¤ê³µì‚¬ êµ´ì°©ë©´ ì•ˆì „ê¸°ìš¸ê¸° ê¸°ì¤€ì— ê´€í•œ ê¸°ìˆ ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ê±´ì„¤ê³µì‚¬ ëŒê´€ì‘ì—… ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 08_general\n",
      "[âŒ ë¯¸ë¶„ë¥˜] ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ ì„¤ê³„ ì§€ì¹¨.md : ê±´ì„¤ê³µì‚¬ì•ˆì „Â·ë³´ê±´ì„¤ê³„ì§€ì¹¨\n",
      "[OK] ê±´ì„¤ê³µì‚¬ì˜ ê³ ì†Œì‘ì—…ëŒ€ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] ê±´ì„¤ê¸°ê³„ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] ê±´ì„¤í˜„ì¥ ìš©ì ‘ìš©ë‹¨ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ 08_general\n",
      "[OK] ê±´ì„¤í˜„ì¥ì˜ ì¤‘ëŸ‰ë¬¼ ì·¨ê¸‰ ì‘ì—…ê³„íšì„œ(ì´ë™ì‹í¬ë ˆì¸) ì‘ì„±ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] ê±´ì¶•ë¬¼ì˜ ì„ê³µì‚¬(ë‚´ì™¸ì¥) ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ê²½ëŸ‰ì² ê³¨ ì²œì¥ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ê³¤ëŒë¼(Gondola) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ê´€ë¡œë§¤ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ê´€ë¡œë§¤ì„¤ê³µì‚¬(ìœ ì••ì‹ ì¶”ì§„ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] êµëŸ‰ ìŠ¬ë˜ë¸Œê±°í‘¸ì§‘ í•´ì²´ìš© ì‘ì—…ëŒ€ì°¨ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] êµëŸ‰ê³µì‚¬(P.S.Mê³µë²•) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] êµëŸ‰ê³µì‚¬(ë¼ë©˜êµ) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] êµëŸ‰ê³µì‚¬ì˜ ì´ë™ì‹ ë¹„ê³„ê³µë²•(MSS) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] êµ´ì°©ê³µì‚¬ ê³„ì¸¡ê´€ë¦¬ ê¸°ìˆ ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] êµ´ì°©ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] êµ´ì°©ê¸° ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ê¸ˆì† ì»¤íŠ¼ì›”(Curtain wall) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ê¸°ì„± ì½˜í¬ë¦¬íŠ¸ íŒŒì¼ í•­íƒ€ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[OK] ë‚™í•˜ë¬¼ ë°©ì§€ë§ ì„¤ì¹˜ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ë‚™í•˜ë¬¼ ë°©í˜¸ì„ ë°˜ ì„¤ì¹˜ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ë‚´ì¥ê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ëƒ‰ë™ëƒ‰ì¥ ë¬¼ë¥˜ì°½ê³  ë‹¨ì—´ê³µì‚¬ í™”ì¬ì˜ˆë°© ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ë‹¨ìˆœ ìŠ¬ë˜ë¸Œ ì½˜í¬ë¦¬íŠ¸ íƒ€ì„¤ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[OK] ë¤í”„íŠ¸ëŸ­ ë° í™”ë¬¼ìë™ì°¨ ì•ˆì „ì‘ì—…ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] ë¯¸ì¥ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ë°€íê³µê°„ì˜ ë°©ìˆ˜ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] ë°œíŒŒê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] ë¸”ë¡ì‹ ë³´ê°•í†  ì˜¹ë²½ ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ì‚¬ì¥êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] ì†Œê·œëª¨ ì² ê·¼ì½˜í¬ë¦¬íŠ¸ êµëŸ‰ê³µì‚¬ ê±°í‘¸ì§‘ ë™ë°”ë¦¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] ìˆ˜ìƒ ë°”ì§€(Barge)ì„  ì´ìš© ê±´ì„¤ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] ìˆ˜ì§ë³´í˜¸ë§ ì„¤ì¹˜ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ìˆ˜ì§í˜• ì¶”ë½ë°©ë§ ì„¤ì¹˜ ê¸°ìˆ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ìŠ¬ë¦½í¼(Slip form) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ì‹œìŠ¤í…œ ë™ë°”ë¦¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ì‹œìŠ¤í…œ ë¹„ê³„ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ì‹œìŠ¤í…œí¼(RCSí¼,ACSí¼ ì¤‘ì‹¬) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ì‹œíŠ¸(Sheet)ë°©ìˆ˜ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ì•„ìŠ¤íŒ”íŠ¸ì½˜í¬ë¦¬íŠ¸ í¬ì¥ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[OK] ì•ˆì „ëŒ€ ì‚¬ìš©ì§€ì¹¨.md â†’ 08_general\n",
      "[OK] ì•¼ê°„ ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 08_general\n",
      "[OK] ì˜¹ë²½(ì½˜í¬ë¦¬íŠ¸ ì˜¹ë²½)ê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ìš°ë¬¼í†µê¸°ì´ˆ ì•ˆì „ë³´ê±´ ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ì´ë™ì‹ ë¹„ê³„ ì„¤ì¹˜ ë° ì‚¬ìš©ì•ˆì „ ê¸°ìˆ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ì´ë™ì‹ í¬ë ˆì¸ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] ì‘ì—…ë°œíŒ ì„¤ì¹˜ ë° ì‚¬ìš©ì•ˆì „ ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ì‘ì—…ì˜ìí˜• ë‹¬ë¹„ê³„ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] ì¡°ê²½ê³µì‚¬(ìˆ˜ëª©ì‹ì¬ì‘ì—…) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 06_finishing\n",
      "[âŒ ë¯¸ë¶„ë¥˜] ì¡°ì ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md : ì¡°ì ê³µì‚¬ì•ˆì „ë³´ê±´ì‘ì—…ê¸°ìˆ ì§€ì¹¨\n",
      "[OK] ì¤‘ì†Œê·œëª¨ ê±´ì„¤ì—…ì²´ ë³¸ì‚¬ì˜ ì•ˆì „ë³´ê±´ê´€ë¦¬ì— ê´€í•œ ì§€ì¹¨.md â†’ 08_general\n",
      "[âŒ ë¯¸ë¶„ë¥˜] ì¤‘ì†Œê·œëª¨ ê´€ë¡œê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md : ì¤‘ì†Œê·œëª¨ê´€ë¡œê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨\n",
      "[OK] ì§€í•˜ë§¤ì„¤ë¬¼ êµ´ì°©ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] ì² ê³¨ê³µì‚¬ ë¬´ì§€ë³´ ê±°í‘¸ì§‘ë™ë°”ë¦¬(ë°í¬í”Œë ˆì´íŠ¸ ê³µë²•)ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[âŒ ë¯¸ë¶„ë¥˜] ì² ê³¨ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md : ì² ê³¨ê³µì‚¬ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨\n",
      "[âŒ ë¯¸ë¶„ë¥˜] ì² íƒ‘ê³µì‚¬ ì•ˆì „ë³´ê±´ê¸°ìˆ ì§€ì¹¨.md : ì² íƒ‘ê³µì‚¬ì•ˆì „ë³´ê±´ê¸°ìˆ ì§€ì¹¨\n",
      "[âŒ ë¯¸ë¶„ë¥˜] ì´ˆê³ ì¸µ ê±´ì¶•ë¬¼ê³µì‚¬(ì¼ë°˜ì‚¬í•­) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md : ì´ˆê³ ì¸µê±´ì¶•ë¬¼ê³µì‚¬(ì¼ë°˜ì‚¬í•­) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨\n",
      "[âŒ ë¯¸ë¶„ë¥˜] ì´ˆê³ ì¸µ ê±´ì¶•ë¬¼ê³µì‚¬(í™”ì¬ì˜ˆë°©) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md : ì´ˆê³ ì¸µê±´ì¶•ë¬¼ê³µì‚¬(í™”ì¬ì˜ˆë°©) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨\n",
      "[âŒ ë¯¸ë¶„ë¥˜] ì¶”ë½ë°©í˜¸ë§ ì„¤ì¹˜ ì§€ì¹¨.md : ì¶”ë½ë°©í˜¸ë§ì„¤ì¹˜ì§€ì¹¨\n",
      "[OK] ì·¨ì•½ì‹œê¸° ê±´ì„¤í˜„ì¥ ì•ˆì „ì‘ì—…ì§€ì¹¨.md â†’ 08_general\n",
      "[OK] ì½˜í¬ë¦¬íŠ¸ê³µì‚¬ì˜ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[OK] íƒ€ì›Œí¬ë ˆì¸ ì„¤ì¹˜, ì¡°ë¦½, í•´ì²´ ì‘ì—…ê³„íšì„œ ì‘ì„±ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] íƒ€ì¼(Tile) ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 06_finishing\n",
      "[OK] íƒ‘ë‹¤ìš´(Top down) ê³µë²• ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] í„°ë„ê³µì‚¬(NATMê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] í„°ë„ê³µì‚¬(NTRê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] í„°ë„ê³µì‚¬(Shield-T.B.Mê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] í„°ë„ê³µì‚¬(ì¹¨ë§¤ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] í„°ë„ê³µì‚¬(í”„ë¡ íŠ¸ì­í‚¹) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 03_tunnel\n",
      "[OK] íŠ¸ëŸ¬ìŠ¤ê±°ë” êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] íŠ¸ëŸ­ íƒ‘ì¬í˜• í¬ë ˆì¸(Cago crane) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] íŒŒì´í”„ ì„œí¬íŠ¸ ë™ë°”ë¦¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 04_scaffold\n",
      "[OK] í”„ë¦¬ìŠ¤íŠ¸ë ˆìŠ¤íŠ¸ ì½˜í¬ë¦¬íŠ¸(PSC) êµëŸ‰ê³µì‚¬ ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] í”„ë¦¬ìºìŠ¤íŠ¸ ì½˜í¬ë¦¬íŠ¸ ê±´ì¶•êµ¬ì¡°ë¬¼ ì¡°ë¦½ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 07_concrete\n",
      "[OK] í•­íƒ€ê¸°, í•­ë°œê¸° ì‚¬ìš© ì‘ì—…ê³„íšì„œ ì‘ì„±ì§€ì¹¨.md â†’ 05_crane\n",
      "[OK] í•´ìƒ RCD í˜„ì¥íƒ€ì„¤ ë§ëšê³µì‚¬(í˜„ìˆ˜êµ, ì‚¬ì¥êµ) ì•ˆì „ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] í•´ì²´ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ 08_general\n",
      "[OK] í˜„ìˆ˜êµ êµëŸ‰ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] í˜„ìˆ˜êµ ì£¼íƒ‘ì‹œê³µ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 01_bridge\n",
      "[OK] í™”í•™í”ŒëœíŠ¸ ê°œë³´ìˆ˜ ê³µì‚¬ ì•ˆì „ë³´ê±´ì‘ì—… ê¸°ìˆ ì§€ì¹¨.md â†’ 08_general\n",
      "[OK] í™ë§‰ì´ê³µì‚¬ (SCW ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(C.I.Pê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(Earth Anchor ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(Soil Nailing ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(ê°•ë„ë§ëš, Sheet Pile)ì˜ ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(ë ì¥ê¸´ì¥ê³µë²•, Prestressed Wale Method) ì•ˆì „ë³´ê±´ ì‘ì—…ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(ì—„ì§€ë§ëš ê³µë²•) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "[OK] í™ë§‰ì´ê³µì‚¬(ì§€í•˜ì—°ì†ë²½) ì•ˆì „ë³´ê±´ì‘ì—… ì§€ì¹¨.md â†’ 02_earth\n",
      "\n",
      "===== ğŸ“Š ë¶„ë¥˜ ìš”ì•½ =====\n",
      "01_bridge : 15ê°œ\n",
      "02_earth : 20ê°œ\n",
      "03_tunnel : 7ê°œ\n",
      "04_scaffold : 18ê°œ\n",
      "05_crane : 9ê°œ\n",
      "06_finishing : 9ê°œ\n",
      "07_concrete : 5ê°œ\n",
      "08_general : 8ê°œ\n",
      "\n",
      "ğŸ‰ DB ìë™ ë¶„ë¥˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# md íŒŒì¼ë“¤ì´ ë“¤ì–´ìˆëŠ” í´ë”\n",
    "md_dir = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/data_md\"\n",
    "\n",
    "# DB ìƒì„± ë£¨íŠ¸ í´ë”\n",
    "db_root = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB\"\n",
    "\n",
    "\n",
    "# ============ ìµœì¢… DB RULES ==============\n",
    "DB_RULES = {\n",
    "    \"01_bridge\": [\n",
    "        \"êµëŸ‰\", \"ê±°ë”\", \"ì•„ì¹˜êµ\", \"ì‚¬ì¥êµ\", \"í˜„ìˆ˜êµ\", \"PSM\", \"RCD\",\n",
    "        \"íŠ¸ëŸ¬ìŠ¤\", \"ë¼ë©˜\", \"MSS\"\n",
    "    ],\n",
    "    \"02_earth\": [\n",
    "        \"í™ë§‰ì´\", \"êµ´ì°©\", \"ê³„ì¸¡ê´€ë¦¬\", \"ì§€í•˜ë§¤ì„¤\", \"SCW\", \"CIP\", \n",
    "        \"Earth\", \"Nailing\", \"Sheet\", \"ì˜¹ë²½\", \"ë³´ê°•í† \",\n",
    "        \"ê¸°ì´ˆ\", \"ê´€ë¡œë§¤ì„¤\", \"ìš°ë¬¼í†µ\"\n",
    "    ],\n",
    "    \"03_tunnel\": [\n",
    "        \"í„°ë„\", \"NATM\", \"NTR\", \"TBM\", \"Shield\",\n",
    "        \"ì¹¨ë§¤\", \"ë°œíŒŒ\", \"í”„ë¡ íŠ¸ì­í‚¹\", \"Top down\", \"íƒ‘ë‹¤ìš´\"\n",
    "    ],\n",
    "    \"04_scaffold\": [\n",
    "        \"ë¹„ê³„\", \"ê°€ì„¤\", \"ì‘ì—…ë°œíŒ\", \"ë°©ì§€ë§\", \"ë°©í˜¸ì„ ë°˜\", \"ë³´í˜¸ë§\",\n",
    "        \"ë‹¬ë¹„ê³„\", \"ì¶”ë½ë°©ë§\", \"ê°€ì„¤ê³„ë‹¨\",\n",
    "        \"ê°±í¼\", \"Slip form\", \"ìŠ¬ë¦½í¼\", \"ë™ë°”ë¦¬\", \"í¼\", \"RCS\", \"ACS\",\n",
    "        \"ì„œí¬íŠ¸\", \"Gondola\", \"ê³¤ëŒë¼\"\n",
    "    ],\n",
    "    \"05_crane\": [\n",
    "        \"í¬ë ˆì¸\", \"ì–‘ì¤‘\", \"ê±´ì„¤ê¸°ê³„\", \"ì¤‘ëŸ‰ë¬¼\", \"íƒ€ì›Œí¬ë ˆì¸\",\n",
    "        \"í•­íƒ€ê¸°\", \"í•­ë°œê¸°\", \"ë¤í”„íŠ¸ëŸ­\", \"í™”ë¬¼ìë™ì°¨\",\n",
    "        \"Barge\", \"ë°”ì§€ì„ \", \"ê³ ì†Œì‘ì—…ëŒ€\"\n",
    "    ],\n",
    "    \"06_finishing\": [\n",
    "        \"ì„ê³µì‚¬\", \"ì»¤íŠ¼ì›”\", \"ë‚´ì¥\", \"ë¯¸ì¥\", \"íƒ€ì¼\", \n",
    "        \"ë‹¨ì—´\", \"ë°©ìˆ˜\", \"ì²œì¥\", \"ì¡°ê²½\", \"ì‹ì¬\"\n",
    "    ],\n",
    "    \"07_concrete\": [\n",
    "        \"ì½˜í¬ë¦¬íŠ¸\", \"ìŠ¬ë˜ë¸Œ\", \"íŒŒì¼í•­íƒ€\", \"í”„ë¦¬ìºìŠ¤íŠ¸\", \"PSC\", \"PC\"\n",
    "    ],\n",
    "    \"08_general\": [\n",
    "        \"ì•ˆì „ëŒ€\", \"ëŒê´€\", \"ì·¨ì•½ì‹œê¸°\", \"ì•¼ê°„\", \"ì„¤ê³„ ì§€ì¹¨\",\n",
    "        \"ë³¸ì‚¬\", \"ì•ˆì „ë³´ê±´ê´€ë¦¬\", \"ìš©ì ‘\", \"ìš©ë‹¨\",\n",
    "        \"í™”í•™í”ŒëœíŠ¸\", \"í•´ì²´ê³µì‚¬\"\n",
    "    ],\n",
    "}\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# DB í´ë” ìƒì„±\n",
    "os.makedirs(db_root, exist_ok=True)\n",
    "for db_name in DB_RULES.keys():\n",
    "    os.makedirs(os.path.join(db_root, db_name), exist_ok=True)\n",
    "\n",
    "# ë¶„ë¥˜ í•¨ìˆ˜\n",
    "def classify_md(title):\n",
    "    for db_name, keywords in DB_RULES.items():\n",
    "        for kw in keywords:\n",
    "            if kw in title:\n",
    "                return db_name\n",
    "    return None  # ì¼ë°˜ì ìœ¼ë¡œ ë‚˜ì˜¤ì§€ ì•Šì§€ë§Œ ì˜ˆì™¸ ëŒ€ë¹„\n",
    "\n",
    "# md íŒŒì¼ ìˆœíšŒ ë° ë¶„ë¥˜\n",
    "classified_count = {db: 0 for db in DB_RULES}\n",
    "\n",
    "for fname in sorted(os.listdir(md_dir)):\n",
    "    if fname.endswith(\".md\"):\n",
    "        src_path = os.path.join(md_dir, fname)\n",
    "\n",
    "        # md íŒŒì¼ ì œëª©(ì²« ë¼ì¸)\n",
    "        with open(src_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            first_line = f.readline().strip()\n",
    "        \n",
    "        title = first_line.lstrip(\"# \").strip()\n",
    "        db_category = classify_md(title)\n",
    "\n",
    "        if db_category is None:\n",
    "            print(f\"[âŒ ë¯¸ë¶„ë¥˜] {fname} : {title}\")\n",
    "            continue\n",
    "\n",
    "        dst_path = os.path.join(db_root, db_category, fname)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "        classified_count[db_category] += 1\n",
    "        print(f\"[OK] {fname} â†’ {db_category}\")\n",
    "\n",
    "print(\"\\n===== ğŸ“Š ë¶„ë¥˜ ìš”ì•½ =====\")\n",
    "for db_name, count in classified_count.items():\n",
    "    print(f\"{db_name} : {count}ê°œ\")\n",
    "\n",
    "print(\"\\nğŸ‰ DB ìë™ ë¶„ë¥˜ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21cfa319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ğŸ“Œ MD ë¶„ë¥˜ ê²€ì¦ ê²°ê³¼ =====\n",
      "\n",
      "ğŸ“„ ì›ë³¸ md íŒŒì¼ ê°œìˆ˜: 99\n",
      "ğŸ“ DB í´ë”ì— ìˆëŠ” md íŒŒì¼ ê°œìˆ˜: 99\n",
      "\n",
      "â­• ëˆ„ë½ëœ íŒŒì¼ ì—†ìŒ\n",
      "\n",
      "â­• DBì—ë§Œ ì¡´ì¬í•˜ëŠ” ì˜ì‹¬ íŒŒì¼ ì—†ìŒ\n",
      "\n",
      "â­• ì¤‘ë³µ ë¶„ë¥˜ëœ íŒŒì¼ ì—†ìŒ\n",
      "\n",
      "===== ê²€ì‚¬ ì™„ë£Œ =====\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ì›ë³¸ md í´ë”\n",
    "md_dir = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/data_md\"\n",
    "\n",
    "# DBê°€ ìƒì„±ëœ ë£¨íŠ¸ í´ë”\n",
    "db_root = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB\"\n",
    "\n",
    "# Step 1. ì›ë³¸ md íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
    "original_files = sorted([f for f in os.listdir(md_dir) if f.endswith(\".md\")])\n",
    "\n",
    "# Step 2. DB í´ë”ì—ì„œ ìˆ˜ì§‘í•œ ëª¨ë“  md íŒŒì¼\n",
    "db_files = []\n",
    "db_map = {}  # íŒŒì¼ëª… â†’ DBí´ë”ëª… ë§¤í•‘\n",
    "\n",
    "for db_name in sorted(os.listdir(db_root)):\n",
    "    db_path = os.path.join(db_root, db_name)\n",
    "    if not os.path.isdir(db_path):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(db_path):\n",
    "        if f.endswith(\".md\"):\n",
    "            db_files.append(f)\n",
    "            db_map[f] = db_name\n",
    "\n",
    "# Step 3. set ë¹„êµ\n",
    "original_set = set(original_files)\n",
    "db_set = set(db_files)\n",
    "\n",
    "missing = original_set - db_set     # DBì— ëˆ„ë½ëœ íŒŒì¼\n",
    "extra = db_set - original_set       # ì›ë³¸ì—” ì—†ëŠ”ë° DBì—ë§Œ ìˆëŠ” íŒŒì¼\n",
    "duplicates = [f for f in db_files if db_files.count(f) > 1]\n",
    "\n",
    "\n",
    "# ============ ì¶œë ¥ ============\n",
    "\n",
    "print(\"\\n===== ğŸ“Œ MD ë¶„ë¥˜ ê²€ì¦ ê²°ê³¼ =====\\n\")\n",
    "\n",
    "print(f\"ğŸ“„ ì›ë³¸ md íŒŒì¼ ê°œìˆ˜: {len(original_files)}\")\n",
    "print(f\"ğŸ“ DB í´ë”ì— ìˆëŠ” md íŒŒì¼ ê°œìˆ˜: {len(db_files)}\\n\")\n",
    "\n",
    "\n",
    "# 1) ëˆ„ë½ëœ íŒŒì¼\n",
    "if missing:\n",
    "    print(\"âŒ DBì— ëˆ„ë½ëœ íŒŒì¼:\")\n",
    "    for m in sorted(missing):\n",
    "        print(f\"   - {m}\")\n",
    "else:\n",
    "    print(\"â­• ëˆ„ë½ëœ íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# 2) DBì—ë§Œ ì¡´ì¬í•˜ëŠ” ì´ìƒ íŒŒì¼\n",
    "if extra:\n",
    "    print(\"âš ï¸ ì›ë³¸ì—” ì—†ê³  DBì—ë§Œ ì¡´ì¬í•˜ëŠ” íŒŒì¼:\")\n",
    "    for e in sorted(extra):\n",
    "        print(f\"   - {e}\")\n",
    "else:\n",
    "    print(\"â­• DBì—ë§Œ ì¡´ì¬í•˜ëŠ” ì˜ì‹¬ íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# 3) ì¤‘ë³µ ë¶„ë¥˜ëœ íŒŒì¼\n",
    "if duplicates:\n",
    "    print(\"âš ï¸ ì¤‘ë³µìœ¼ë¡œ ì—¬ëŸ¬ DBì— í¬í•¨ëœ íŒŒì¼:\")\n",
    "    seen = set()\n",
    "    for d in duplicates:\n",
    "        if d not in seen:\n",
    "            print(f\"   - {d}  (ì˜ˆ: {db_map.get(d)})\")\n",
    "            seen.add(d)\n",
    "else:\n",
    "    print(\"â­• ì¤‘ë³µ ë¶„ë¥˜ëœ íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "print(\"\\n===== ê²€ì‚¬ ì™„ë£Œ =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b87d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 01_bridge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01_bridge ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 2453.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB/01_bridge/01_bridge_chunks.jsonl (ì´ 347 ì²­í¬)\n",
      "\n",
      "ğŸ“ Processing DB: 02_earth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02_earth ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 2993.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB/02_earth/02_earth_chunks.jsonl (ì´ 460 ì²­í¬)\n",
      "\n",
      "ğŸ“ Processing DB: 03_tunnel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03_tunnel ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 2090.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB/03_tunnel/03_tunnel_chunks.jsonl (ì´ 223 ì²­í¬)\n",
      "\n",
      "ğŸ“ Processing DB: 04_scaffold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04_scaffold ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 3933.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB/04_scaffold/04_scaffold_chunks.jsonl (ì´ 319 ì²­í¬)\n",
      "\n",
      "ğŸ“ Processing DB: 05_crane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05_crane ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 2244.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB/05_crane/05_crane_chunks.jsonl (ì´ 272 ì²­í¬)\n",
      "\n",
      "ğŸ“ Processing DB: 06_finishing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06_finishing ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 3787.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB/06_finishing/06_finishing_chunks.jsonl (ì´ 176 ì²­í¬)\n",
      "\n",
      "ğŸ“ Processing DB: 07_concrete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07_concrete ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 3028.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB/07_concrete/07_concrete_chunks.jsonl (ì´ 153 ì²­í¬)\n",
      "\n",
      "ğŸ“ Processing DB: 08_general\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08_general ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 2428.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ â†’ /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB/08_general/08_general_chunks.jsonl (ì´ 318 ì²­í¬)\n",
      "\n",
      "ğŸ‰ ëª¨ë“  DB ì²­í‚¹ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ===== 1ï¸âƒ£ ê²½ë¡œ ì„¤ì • =====\n",
    "DB_ROOT = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB\"\n",
    "\n",
    "# ===== 2ï¸âƒ£ ì„¹ì…˜ ë¶„ë¦¬ í•¨ìˆ˜ =====\n",
    "def split_by_heading(text: str):\n",
    "    \"\"\"# í—¤ë”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì„¹ì…˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆ”\"\"\"\n",
    "    sections = re.split(r'(?=^# )', text, flags=re.MULTILINE)\n",
    "    return [s.strip() for s in sections if s.strip()]\n",
    "\n",
    "# ===== 3ï¸âƒ£ ë‚´ë¶€ ì²­í‚¹ Splitter =====\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "\n",
    "# ===== 4ï¸âƒ£ ì „ì²´ DB í´ë” ìˆœíšŒ =====\n",
    "for db_folder in sorted(os.listdir(DB_ROOT)):\n",
    "    db_path = os.path.join(DB_ROOT, db_folder)\n",
    "    if not os.path.isdir(db_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸ“ Processing DB: {db_folder}\")\n",
    "\n",
    "    md_files = [f for f in os.listdir(db_path) if f.endswith(\".md\")]\n",
    "    chunks = []\n",
    "\n",
    "    # ===== 5ï¸âƒ£ md íŒŒì¼ ìˆœíšŒ =====\n",
    "    for file_name in tqdm(md_files, desc=f\"{db_folder} ì²˜ë¦¬ ì¤‘\"):\n",
    "        file_path = os.path.join(db_path, file_name)\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_name} ({e})\")\n",
    "            continue\n",
    "\n",
    "        # ì„¹ì…˜ ë¶„ë¦¬\n",
    "        sections = split_by_heading(raw_text)\n",
    "\n",
    "        # ê° ì„¹ì…˜ ë‚´ë¶€ ì²­í‚¹\n",
    "        for sec in sections:\n",
    "            heading_match = re.match(r\"^#\\s*(.*)\", sec)\n",
    "            heading = heading_match.group(1).strip() if heading_match else \"ë³¸ë¬¸\"\n",
    "\n",
    "            split_texts = splitter.split_text(sec)\n",
    "            for idx, chunk in enumerate(split_texts):\n",
    "                chunks.append({\n",
    "                    \"db\": db_folder,                     # ì–´ë–¤ DBì—ì„œ ë‚˜ì˜¨ ì²­í¬ì¸ê°€?\n",
    "                    \"file\": file_name,                   # ì›ë³¸ ë¬¸ì„œëª…\n",
    "                    \"section\": heading,                  # í—¤ë” ì œëª©\n",
    "                    \"chunk_id\": idx,                     # ë¬¸ì„œ ë‚´ ì²­í¬ ë²ˆí˜¸\n",
    "                    \"source_path\": file_path,            # ì „ì²´ ê²½ë¡œ\n",
    "                    \"content\": chunk                     # ì‹¤ì œ í…ìŠ¤íŠ¸\n",
    "                })\n",
    "\n",
    "    # ===== 6ï¸âƒ£ DBë³„ chunks.jsonl ì €ì¥ =====\n",
    "    out_path = os.path.join(db_path, f\"{db_folder}_chunks.jsonl\")\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as jf:\n",
    "        for c in chunks:\n",
    "            jf.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ â†’ {out_path} (ì´ {len(chunks)} ì²­í¬)\")\n",
    "\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë“  DB ì²­í‚¹ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ae4107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“ DB í´ë” ë³µì œ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 314.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… DB â†’ DB2 ë³€í™˜ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "DB_ROOT = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB\"\n",
    "DB2_ROOT = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB2\"\n",
    "\n",
    "# DB2 ë£¨íŠ¸ í´ë” ìƒì„±\n",
    "os.makedirs(DB2_ROOT, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_hash_depth(line):\n",
    "    \"\"\"'#', '##', '###' ì˜ ê¹Šì´ ê³„ì‚°\"\"\"\n",
    "    match = re.match(r\"^(#+)\\s*\", line)\n",
    "    return len(match.group(1)) if match else 0\n",
    "\n",
    "\n",
    "def extract_numbering_and_title(line):\n",
    "    \"\"\"\n",
    "    '# 5.2 ì„¤ì¹˜ì‘ì—…' â†’ ('5.2', 'ì„¤ì¹˜ì‘ì—…')\n",
    "    \"\"\"\n",
    "    line_no_hash = re.sub(r\"^#+\\s*\", \"\", line).strip()\n",
    "    match = re.match(r\"^(\\d+(?:\\.\\d+)*)(?:\\s*)(.*)\", line_no_hash)\n",
    "    if not match:\n",
    "        return None, None\n",
    "    return match.group(1), match.group(2).strip()\n",
    "\n",
    "\n",
    "def numbering_to_depth(numbering):\n",
    "    \"\"\"'5.2.1' â†’ 3\"\"\"\n",
    "    return numbering.count(\".\") + 1\n",
    "\n",
    "\n",
    "def process_md_line(line):\n",
    "    stripped = line.strip()\n",
    "\n",
    "    # --- 1) '#' ì—†ëŠ” ë¼ì¸ì€ ê·¸ëŒ€ë¡œ ---\n",
    "    if not stripped.startswith(\"#\"):\n",
    "        return line\n",
    "\n",
    "    # --- 2) numbering ì¶”ì¶œ ---\n",
    "    numbering, title = extract_numbering_and_title(stripped)\n",
    "    if not numbering:\n",
    "        return line   # ìˆ«ìë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´ ì œëª©ì´ ì•„ë‹˜ â†’ ê·¸ëŒ€ë¡œ ë‘ \n",
    "\n",
    "    # --- 3) í˜„ì¬ '#' ê¹Šì´ ---\n",
    "    current_depth = get_hash_depth(stripped)\n",
    "\n",
    "    # --- 4) ì˜¬ë°”ë¥¸ '#' ê¹Šì´ ê³„ì‚° ---\n",
    "    correct_depth = numbering_to_depth(numbering)\n",
    "\n",
    "    # --- 5) ì´ë¯¸ ì˜¬ë°”ë¥´ë©´ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ ---\n",
    "    if current_depth == correct_depth:\n",
    "        return line\n",
    "\n",
    "    # --- 6) ìˆ˜ì •í•´ì•¼ í•˜ëŠ” ê²½ìš° ----\n",
    "    hashes = \"#\" * correct_depth\n",
    "    new_line = f\"{hashes} {numbering}\"\n",
    "    if title:\n",
    "        new_line += f\" {title}\"\n",
    "\n",
    "    return new_line + \"\\n\"\n",
    "\n",
    "\n",
    "def process_md_file(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    new_lines = [process_md_line(line) for line in lines]\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(new_lines)\n",
    "\n",
    "\n",
    "# ============================\n",
    "#     DB â†’ DB2 ì „ì²´ ë³µì œ ì‹¤í–‰\n",
    "# ============================\n",
    "\n",
    "for folder in tqdm(os.listdir(DB_ROOT), desc=\"ğŸ“ DB í´ë” ë³µì œ ì¤‘\"):\n",
    "    folder_path = os.path.join(DB_ROOT, folder)\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    # DB2ì—ì„œ ë™ì¼ í´ë” ìƒì„±\n",
    "    new_folder_path = os.path.join(DB2_ROOT, folder)\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(folder_path):\n",
    "        old_file = os.path.join(folder_path, fname)\n",
    "        new_file = os.path.join(new_folder_path, fname)\n",
    "\n",
    "        # md íŒŒì¼ì´ë©´ ì²˜ë¦¬\n",
    "        if fname.endswith(\".md\"):\n",
    "            process_md_file(old_file, new_file)\n",
    "        else:\n",
    "            # mdê°€ ì•„ë‹Œ íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ë³µì‚¬\n",
    "            shutil.copy(old_file, new_file)\n",
    "\n",
    "print(\"\\nâœ… DB â†’ DB2 ë³€í™˜ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00632bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 01_bridge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01_bridge: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 1407.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 02_earth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02_earth: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 1593.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 03_tunnel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03_tunnel: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 995.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 04_scaffold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04_scaffold: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 2211.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 05_crane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05_crane: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 1068.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 06_finishing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06_finishing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 2097.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 07_concrete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07_concrete: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1465.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Processing DB: 08_general\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08_general: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 1174.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ ëª¨ë“  DB2 â†’ DB2_chunks ì²­í‚¹ + Hierarchy ìƒì„± ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "DB2_ROOT = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB\"\n",
    "OUTPUT_ROOT = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB_chunks\"\n",
    "\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) ë¬¸ì„œ ì „ì²´ì—ì„œ Headingì„ ì¶”ì¶œí•´ ì „ì²´ ê³„ì¸µ íŠ¸ë¦¬ êµ¬ì„±\n",
    "# ------------------------------------------------------------\n",
    "def extract_all_headings(text):\n",
    "    \"\"\"\n",
    "    ë¬¸ì„œ ì „ì²´ ì œëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜\n",
    "    ex: [{'number': '5', 'title':'ì£¼íƒ‘ì•ˆì „ì‘ì—…','depth':1}, ...]\n",
    "    \"\"\"\n",
    "    headings = []\n",
    "    pattern = r\"^(#{1,4})\\s+(\\d+(?:\\.\\d+)*)(?:\\s*)(.*)$\"\n",
    "\n",
    "    for line in text.split(\"\\n\"):\n",
    "        m = re.match(pattern, line.strip())\n",
    "        if m:\n",
    "            hashes, number, title = m.groups()\n",
    "            depth = len(hashes)\n",
    "            headings.append({\n",
    "                \"number\": number,\n",
    "                \"title\": title.strip(),\n",
    "                \"depth\": depth\n",
    "            })\n",
    "\n",
    "    return headings\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) íŠ¹ì • section_numberë¥¼ ê¸°ì¤€ìœ¼ë¡œ hierarchy ìë™ êµ¬ì„±\n",
    "# ------------------------------------------------------------\n",
    "def build_hierarchy(all_headings, target_number):\n",
    "    \"\"\"\n",
    "    ex: target_number=\"5.2.1\" â†’ ìƒìœ„ \"5\", \"5.2\" ìë™ í¬í•¨\n",
    "    \"\"\"\n",
    "    target_levels = target_number.split(\".\")\n",
    "    hierarchy = []\n",
    "\n",
    "    for h in all_headings:\n",
    "        h_levels = h[\"number\"].split(\".\")\n",
    "\n",
    "        if len(h_levels) <= len(target_levels):\n",
    "            if h_levels == target_levels[:len(h_levels)]:\n",
    "                hierarchy.append(f\"{h['number']} {h['title']}\")\n",
    "\n",
    "    return hierarchy\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Heading ë‹¨ìœ„ë¡œ ì„¹ì…˜ ë¶„ë¦¬\n",
    "# ------------------------------------------------------------\n",
    "def split_by_sections(text):\n",
    "    pattern = r\"(?=^#{1,4}\\s+\\d+(?:\\.\\d+)* )\"\n",
    "    sections = re.split(pattern, text, flags=re.MULTILINE)\n",
    "\n",
    "    cleaned = []\n",
    "    for sec in sections:\n",
    "        sec = sec.strip()\n",
    "        if sec.startswith(\"#\"):\n",
    "            cleaned.append(sec)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) ê°œë³„ section í—¤ë” ì •ë³´ íŒŒì‹±\n",
    "# ------------------------------------------------------------\n",
    "def extract_section_heading(section_text):\n",
    "    first_line = section_text.split(\"\\n\")[0].strip()\n",
    "    m = re.match(r\"^(#{1,4})\\s+(\\d+(?:\\.\\d+)*)(?:\\s*)(.*)$\", first_line)\n",
    "\n",
    "    if not m:\n",
    "        return None, None, None\n",
    "\n",
    "    hashes, number, title = m.groups()\n",
    "    heading_text = f\"{number} {title}\".strip()\n",
    "    depth = len(hashes)\n",
    "\n",
    "    return heading_text, number, depth\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Chunk splitter ì„¤ì •\n",
    "# ------------------------------------------------------------\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) DB2 ì „ì²´ ì²­í‚¹ ìˆ˜í–‰\n",
    "# ------------------------------------------------------------\n",
    "for db_name in sorted(os.listdir(DB2_ROOT)):\n",
    "    db_path = os.path.join(DB2_ROOT, db_name)\n",
    "    if not os.path.isdir(db_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸ“ Processing DB: {db_name}\")\n",
    "\n",
    "    # â”€ DB ì´ë¦„ ê·¸ëŒ€ë¡œ í´ë” ìƒì„± â”€\n",
    "    out_folder = os.path.join(OUTPUT_ROOT, db_name)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    out_jsonl = os.path.join(out_folder, f\"{db_name}_chunks.jsonl\")\n",
    "\n",
    "    with open(out_jsonl, \"w\", encoding=\"utf-8\") as out_f:\n",
    "\n",
    "        # md íŒŒì¼ë“¤ íƒìƒ‰\n",
    "        for file_name in tqdm(os.listdir(db_path), desc=db_name):\n",
    "            if not file_name.endswith(\".md\"):\n",
    "                continue\n",
    "\n",
    "            md_path = os.path.join(db_path, file_name)\n",
    "\n",
    "            # â”€ Raw text ì½ê¸° â”€\n",
    "            with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_text = f.read()\n",
    "\n",
    "            # â”€ ë¬¸ì„œ ì „ì²´ Heading ìˆ˜ì§‘ â”€\n",
    "            all_headings = extract_all_headings(raw_text)\n",
    "\n",
    "            # â”€ ì„¹ì…˜ ë¶„ë¦¬ â”€\n",
    "            sections = split_by_sections(raw_text)\n",
    "\n",
    "            for sec in sections:\n",
    "                section_text, section_number, depth = extract_section_heading(sec)\n",
    "                if not section_number:\n",
    "                    continue\n",
    "\n",
    "                # â”€ Hierarchy ìë™ êµ¬ì„± â”€\n",
    "                hierarchy_list = build_hierarchy(all_headings, section_number)\n",
    "                hierarchy_str = \" > \".join(hierarchy_list)\n",
    "\n",
    "                # ì„¹ì…˜ ë³¸ë¬¸ ì¶”ì¶œ\n",
    "                body = sec.split(\"\\n\", 1)[1] if \"\\n\" in sec else \"\"\n",
    "\n",
    "                # â”€ ë‚´ë¶€ chunking â”€\n",
    "                chunks = splitter.split_text(body)\n",
    "\n",
    "                # â”€ Chunk ì €ì¥ â”€\n",
    "                for idx, chunk in enumerate(chunks):\n",
    "\n",
    "                    record = {\n",
    "                        \"db\": db_name,\n",
    "                        \"file\": file_name,\n",
    "                        \"section\": section_text,\n",
    "                        \"section_number\": section_number,\n",
    "                        \"hierarchy\": hierarchy_list,\n",
    "                        \"hierarchy_str\": hierarchy_str,\n",
    "                        \"chunk_id\": idx,\n",
    "                        \"source_path\": md_path,\n",
    "                        \"content\": chunk\n",
    "                    }\n",
    "\n",
    "                    out_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë“  DB2 â†’ DB2_chunks ì²­í‚¹ + Hierarchy ìƒì„± ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87ea16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ Chunk Quality Report ìƒì„± ì™„ë£Œ!\n",
      "ğŸ“„ ì €ì¥ ìœ„ì¹˜: /home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/chunk_quality_report.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "CHUNK_ROOT = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB_chunks_cleaned\"\n",
    "REPORT_PATH = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/chunk_quality_report.json\"\n",
    "\n",
    "# ìœ ì‚¬ë„ ì¤‘ë³µ ê²€ì‚¬ ëª¨ë¸ (ë¹ ë¥´ê³  ê°€ë³ê³  ì¢‹ìŒ)\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "def section_depth(num):\n",
    "    return len(num.split(\".\"))\n",
    "\n",
    "\n",
    "report = {}\n",
    "\n",
    "# ================================\n",
    "# DBë³„ í’ˆì§ˆ ê²€ì‚¬ ì‹œì‘\n",
    "# ================================\n",
    "for db_name in sorted(os.listdir(CHUNK_ROOT)):\n",
    "    db_folder = os.path.join(CHUNK_ROOT, db_name)\n",
    "    if not os.path.isdir(db_folder):\n",
    "        continue\n",
    "\n",
    "    jsonl_path = os.path.join(db_folder, f\"{db_name}_chunks.jsonl\")\n",
    "    if not os.path.exists(jsonl_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸ” Checking DB: {db_name}\")\n",
    "    chunks = load_jsonl(jsonl_path)\n",
    "\n",
    "    total_chunks = len(chunks)\n",
    "\n",
    "    too_short = 0\n",
    "    too_long = 0\n",
    "    hierarchy_missing = 0\n",
    "    hierarchy_mismatch = 0\n",
    "    problematic_sections = []\n",
    "\n",
    "    # ê¸¸ì´ ê²€ì‚¬\n",
    "    for c in chunks:\n",
    "        length = len(c[\"content\"])\n",
    "        if length < 50:\n",
    "            too_short += 1\n",
    "            problematic_sections.append({\"section\": c[\"section\"], \"reason\": \"too short\"})\n",
    "        if length > 2000:\n",
    "            too_long += 1\n",
    "            problematic_sections.append({\"section\": c[\"section\"], \"reason\": \"too long\"})\n",
    "\n",
    "        # hierarchy ëˆ„ë½ ê²€ì‚¬\n",
    "        if not c[\"hierarchy\"]:\n",
    "            hierarchy_missing += 1\n",
    "            problematic_sections.append({\"section\": c[\"section\"], \"reason\": \"hierarchy missing\"})\n",
    "\n",
    "        # hierarchy depth mismatch ê²€ì‚¬\n",
    "        if len(c[\"hierarchy\"]) != section_depth(c[\"section_number\"]):\n",
    "            hierarchy_mismatch += 1\n",
    "            problematic_sections.append({\"section\": c[\"section\"], \"reason\": \"hierarchy mismatch\"})\n",
    "\n",
    "\n",
    "    # ì¤‘ë³µ ê²€ì‚¬ (ë¬¸ì¥ì´ ê¸´ chunkë§Œ ì„ íƒí•˜ì—¬ ê²€ì‚¬ ë¶€ë‹´ ì¤„ì´ê¸°)\n",
    "    print(\"   ğŸ‘‰ Checking duplicate similarity (this may take ~15s)\")\n",
    "    texts = [c[\"content\"] for c in chunks]\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "    cosine = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "    duplicate_count = 0\n",
    "    for i in range(total_chunks):\n",
    "        for j in range(i + 1, total_chunks):\n",
    "            if cosine[i][j] > 0.95:\n",
    "                duplicate_count += 1\n",
    "                problematic_sections.append({\n",
    "                    \"section\": chunks[i][\"section\"],\n",
    "                    \"reason\": \"duplicate chunk (>0.95 cosine)\"\n",
    "                })\n",
    "\n",
    "    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\n",
    "    error_rate = (\n",
    "        too_short +\n",
    "        too_long +\n",
    "        hierarchy_missing +\n",
    "        hierarchy_mismatch +\n",
    "        duplicate_count\n",
    "    ) / total_chunks\n",
    "\n",
    "    quality_score = round(max(0, 1 - error_rate), 3)\n",
    "\n",
    "\n",
    "    # DBë³„ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "    report[db_name] = {\n",
    "        \"total_chunks\": total_chunks,\n",
    "        \"too_short\": too_short,\n",
    "        \"too_long\": too_long,\n",
    "        \"hierarchy_missing\": hierarchy_missing,\n",
    "        \"hierarchy_mismatch\": hierarchy_mismatch,\n",
    "        \"duplicate_chunks\": duplicate_count,\n",
    "        \"problematic_sections\": problematic_sections[:50],  # ë„ˆë¬´ ë§ìœ¼ë©´ 50ê°œë§Œ\n",
    "        \"quality_score\": quality_score\n",
    "    }\n",
    "\n",
    "\n",
    "# ================================\n",
    "# ìµœì¢… ë¦¬í¬íŠ¸ JSON ì €ì¥\n",
    "# ================================\n",
    "with open(REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(report, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nğŸ‰ Chunk Quality Report ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“„ ì €ì¥ ìœ„ì¹˜: {REPORT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f38052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Evaluating CLEAN DB: 01_bridge\n",
      "\n",
      "ğŸ” Evaluating CLEAN DB: 02_earth\n",
      "\n",
      "ğŸ” Evaluating CLEAN DB: 03_tunnel\n",
      "\n",
      "ğŸ” Evaluating CLEAN DB: 04_scaffold\n",
      "\n",
      "ğŸ” Evaluating CLEAN DB: 05_crane\n",
      "\n",
      "ğŸ” Evaluating CLEAN DB: 06_finishing\n",
      "\n",
      "ğŸ” Evaluating CLEAN DB: 07_concrete\n",
      "\n",
      "ğŸ” Evaluating CLEAN DB: 08_general\n",
      "\n",
      "ğŸ“„ JSON Report saved to:\n",
      "/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/db_quality_report_clean.json\n",
      "\n",
      "\n",
      "================== CLEAN CHUNK QUALITY SUMMARY ==================\n",
      "\n",
      "DB Name         Total    Mismatch   Dup      Score \n",
      "------------------------------------------------------------\n",
      "01_bridge       168      0          0        1.0   \n",
      "02_earth        253      0          0        1.0   \n",
      "03_tunnel       129      0          0        1.0   \n",
      "04_scaffold     161      0          0        1.0   \n",
      "05_crane        180      0          0        1.0   \n",
      "06_finishing    85       0          0        1.0   \n",
      "07_concrete     63       0          0        1.0   \n",
      "08_general      181      0          0        1.0   \n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ============================\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "# ============================\n",
    "ROOT = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data\"\n",
    "CLEAN_DIR = f\"{ROOT}/DB_chunks_cleaned\"\n",
    "OUT_REPORT = f\"{ROOT}/db_quality_report_clean.json\"\n",
    "\n",
    "# ============================\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "# ============================\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ============================\n",
    "# 1) Hierarchy mismatch ì²´í¬ í•¨ìˆ˜\n",
    "# ============================\n",
    "def detect_hierarchy_mismatch(section):\n",
    "    pattern = r\"^(#+)\\s+(\\d+(\\.\\d+){0,2})\"\n",
    "    m = re.match(pattern, section)\n",
    "    if not m:\n",
    "        return True  # ìˆ«ì í—¤ë” êµ¬ì¡°ê°€ ì•„ë‹ˆë©´ mismatch\n",
    "\n",
    "    hashes = m.group(1)\n",
    "    numbering = m.group(2)\n",
    "\n",
    "    depth_expected = numbering.count(\".\") + 1\n",
    "    depth_actual = len(hashes)\n",
    "\n",
    "    return depth_expected != depth_actual\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2) Duplicate chunk íƒì§€\n",
    "# ============================\n",
    "def detect_duplicates(chunks, threshold=0.95):\n",
    "    docs = [c[\"content\"] for c in chunks]\n",
    "    embeds = model.encode(docs, convert_to_tensor=True)\n",
    "\n",
    "    duplicates = []\n",
    "    used = set()\n",
    "\n",
    "    for i in range(len(docs)):\n",
    "        if i in used:\n",
    "            continue\n",
    "\n",
    "        sims = util.cos_sim(embeds[i], embeds)[0].cpu().numpy()\n",
    "        dup_idx = np.where(sims >= threshold)[0]\n",
    "\n",
    "        for j in dup_idx:\n",
    "            if j != i:\n",
    "                duplicates.append((i, j, chunks[j][\"section\"]))\n",
    "                used.add(j)\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ğŸ”¥ CLEAN DB ì „ì²´ í‰ê°€\n",
    "# ============================\n",
    "results = {}\n",
    "\n",
    "for db in sorted(os.listdir(CLEAN_DIR)):\n",
    "    db_path = os.path.join(CLEAN_DIR, db)\n",
    "    if not os.path.isdir(db_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸ” Evaluating CLEAN DB: {db}\")\n",
    "\n",
    "    jsonl_path = os.path.join(db_path, f\"{db}_chunks_cleaned.jsonl\")\n",
    "    if not os.path.exists(jsonl_path):\n",
    "        print(\"âš  íŒŒì¼ ì—†ìŒ â€” SKIP\")\n",
    "        continue\n",
    "\n",
    "    chunks = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            chunks.append(json.loads(line))\n",
    "\n",
    "    total = len(chunks)\n",
    "\n",
    "    # === Hierarchy mismatch ===\n",
    "    hierarchy_mismatch = []\n",
    "    for c in chunks:\n",
    "        if detect_hierarchy_mismatch(c[\"section\"]):\n",
    "            hierarchy_mismatch.append(c[\"section\"])\n",
    "\n",
    "    # === Duplicate detection ===\n",
    "    duplicate_chunks = detect_duplicates(chunks)\n",
    "\n",
    "    # === Score ê³„ì‚° ===\n",
    "    score = (\n",
    "        1\n",
    "        - (len(hierarchy_mismatch) / total) * 0.5\n",
    "        - (len(duplicate_chunks) / total) * 0.5\n",
    "    )\n",
    "\n",
    "    results[db] = {\n",
    "        \"total_chunks\": total,\n",
    "        \"hierarchy_mismatch\": len(hierarchy_mismatch),\n",
    "        \"duplicate_chunks\": len(duplicate_chunks),\n",
    "        \"problematic_sections\": list(set(hierarchy_mismatch)),\n",
    "        \"quality_score\": round(score, 3),\n",
    "    }\n",
    "\n",
    "# ============================\n",
    "# JSON ë¦¬í¬íŠ¸ ì €ì¥\n",
    "# ============================\n",
    "with open(OUT_REPORT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nğŸ“„ JSON Report saved to:\\n{OUT_REPORT}\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ğŸ“Œ ë³´ê¸° ì¢‹ì€ í‘œ í˜•íƒœì˜ REPORT ì¶œë ¥\n",
    "# ============================\n",
    "print(\"\\n\\n================== CLEAN CHUNK QUALITY SUMMARY ==================\\n\")\n",
    "print(f\"{'DB Name':<15} {'Total':<8} {'Mismatch':<10} {'Dup':<8} {'Score':<6}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for db, r in results.items():\n",
    "    print(\n",
    "        f\"{db:<15} \"\n",
    "        f\"{r['total_chunks']:<8} \"\n",
    "        f\"{r['hierarchy_mismatch']:<10} \"\n",
    "        f\"{r['duplicate_chunks']:<8} \"\n",
    "        f\"{r['quality_score']:<6}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "DESCRIPTIONS = {\n",
    "    \"01_bridge\": {\n",
    "        \"name\": \"Bridge Construction Safety DB\",\n",
    "        \"domain\": \"êµëŸ‰ê³µì‚¬\",\n",
    "        \"purpose\": \"êµëŸ‰ ì‹œê³µê³¼ ê´€ë ¨ëœ ëª¨ë“  ê³µì •(FCM, ILM, PSM, PCTê±°ë” ë“±)ì— ëŒ€í•œ ì•ˆì „ì‘ì—… ì§€ì¹¨ê³¼ ì‚¬ê³  ì˜ˆë°© ê¸°ì¤€ì„ ì œê³µí•œë‹¤.\",\n",
    "        \"covers\": [\"êµëŸ‰ ìƒë¶€ê³µ\", \"ê±°ë” ì„¤ì¹˜\", \"ìŠ¬ë˜ë¸Œ ê±°í‘¸ì§‘\", \"í˜„ìˆ˜êµ ì‹œê³µ\"],\n",
    "        \"common_accidents\": [\"ê±°í‘¸ì§‘ ë¶•ê´´\", \"ì¶”ë½\", \"ë‚™í•˜ë¬¼\"],\n",
    "        \"best_for_queries\": [\"êµëŸ‰ ê±°í‘¸ì§‘ ë¶•ê´´\", \"ê±°ë” ì¸ì–‘ ì‚¬ê³ \"]\n",
    "    },\n",
    "    \"02_earth\": {\n",
    "        \"name\": \"Earthwork & Excavation Safety DB\",\n",
    "        \"domain\": \"í† ê³µì‚¬/êµ´ì°©\",\n",
    "        \"purpose\": \"êµ´ì°©ê³µì‚¬, í™ë§‰ì´ ì§€ë³´ê³µ, SCW/CIP ë“± ì§€ë°˜ ê´€ë ¨ ê³µì •ì˜ ë¶•ê´´Â·ë§¤ëª° ì‚¬ê³  ì˜ˆë°© ì§€ì¹¨ ì œê³µ.\",\n",
    "        \"covers\": [\"í„°íŒŒê¸°\", \"í™ë§‰ì´\", \"SCW\", \"CIP\"],\n",
    "        \"common_accidents\": [\"ë¶•ê´´\", \"ë§¤ëª°\"],\n",
    "        \"best_for_queries\": [\"í† ì‚¬ ë¶•ê´´\", \"í™ë§‰ì´ ë³€í˜• ì‚¬ê³ \"]\n",
    "    },\n",
    "    \"03_tunnel\": {\n",
    "        \"name\": \"Tunnel Construction Safety DB\",\n",
    "        \"domain\": \"í„°ë„\",\n",
    "        \"purpose\": \"NATM, TBM, ë°œíŒŒ ë“± í„°ë„ êµ´ì°© ê´€ë ¨ ì•ˆì „ì§€ì¹¨ ì œê³µ.\",\n",
    "        \"covers\": [\"ë°œíŒŒ\", \"ìˆí¬ë¦¬íŠ¸\", \"ë¡ë³¼íŠ¸\", \"ì§€ë³´ê³µ\"],\n",
    "        \"common_accidents\": [\"ë‚™ì„\", \"ë¶•ë½\", \"ê°€ìŠ¤ í­ë°œ\"],\n",
    "        \"best_for_queries\": [\"í„°ë„ ë¶•ë½ ì‚¬ê³ \", \"ë°œíŒŒ ì‘ì—… ì‚¬ê³ \"]\n",
    "    },\n",
    "    \"04_scaffold\": {\n",
    "        \"name\": \"Scaffolding Safety DB\",\n",
    "        \"domain\": \"ë¹„ê³„/ê°€ì„¤\",\n",
    "        \"purpose\": \"ë¹„ê³„, ë‹¬ë¹„ê³„, ì´ë™ì‹ ë¹„ê³„ ë“± ê³ ì†Œì‘ì—… ì•ˆì „ê¸°ì¤€ ì œê³µ.\",\n",
    "        \"covers\": [\"ë¹„ê³„ ì„¤ì¹˜\", \"ë‹¬ë¹„ê³„\", \"ì´ë™ì‹ ë¹„ê³„\"],\n",
    "        \"common_accidents\": [\"ì¶”ë½\", \"ë¹„ê³„ ë¶•ê´´\"],\n",
    "        \"best_for_queries\": [\"ë¹„ê³„ ì¶”ë½ ì‚¬ê³ \"]\n",
    "    },\n",
    "    \"05_crane\": {\n",
    "        \"name\": \"Crane & Lifting Safety DB\",\n",
    "        \"domain\": \"íƒ€ì›Œí¬ë ˆì¸/ì¸ì–‘\",\n",
    "        \"purpose\": \"íƒ€ì›Œí¬ë ˆì¸ ë° ì¤‘ëŸ‰ë¬¼ ì¸ì–‘ ì‘ì—… ì•ˆì „ì§€ì¹¨ ì œê³µ.\",\n",
    "        \"covers\": [\"íƒ€ì›Œí¬ë ˆì¸\", \"ì´ë™ì‹ í¬ë ˆì¸\"],\n",
    "        \"common_accidents\": [\"ì „ë„\", \"ë‚™í•˜\", \"ë¡œí”„ íŒŒë‹¨\"],\n",
    "        \"best_for_queries\": [\"í¬ë ˆì¸ ì „ë„\", \"ì¸ì–‘ë¬¼ ë‚™í•˜\"]\n",
    "    },\n",
    "    \"06_finishing\": {\n",
    "        \"name\": \"Finishing Construction Safety DB\",\n",
    "        \"domain\": \"ë§ˆê°\",\n",
    "        \"purpose\": \"ì‹¤ë‚´ ë§ˆê°ê³µì‚¬ ì•ˆì „ì§€ì¹¨ ì œê³µ.\",\n",
    "        \"covers\": [\"ì„ê³ ë³´ë“œ\", \"ì°½í˜¸\", \"ë‚´ë¶€ ë§ˆê°\"],\n",
    "        \"common_accidents\": [\"ì‚¬ë‹¤ë¦¬ ì „ë„\", \"ë‚™í•˜\"],\n",
    "        \"best_for_queries\": [\"ì‹¤ë‚´ ì‚¬ë‹¤ë¦¬ ì‚¬ê³ \"]\n",
    "    },\n",
    "    \"07_concrete\": {\n",
    "        \"name\": \"Concrete & Formwork Safety DB\",\n",
    "        \"domain\": \"ì½˜í¬ë¦¬íŠ¸\",\n",
    "        \"purpose\": \"íƒ€ì„¤, ê±°í‘¸ì§‘, ë™ë°”ë¦¬ ì‘ì—… ì•ˆì „ê¸°ì¤€ ì œê³µ.\",\n",
    "        \"covers\": [\"ê±°í‘¸ì§‘\", \"ë™ë°”ë¦¬\", \"íƒ€ì„¤\"],\n",
    "        \"common_accidents\": [\"ê±°í‘¸ì§‘ ë¶•ê´´\", \"ë™ë°”ë¦¬ ì¢Œêµ´\"],\n",
    "        \"best_for_queries\": [\"ë™ë°”ë¦¬ ë¶•ê´´\", \"íƒ€ì„¤ ì‚¬ê³ \"]\n",
    "    },\n",
    "    \"08_general\": {\n",
    "        \"name\": \"General Construction Safety DB\",\n",
    "        \"domain\": \"ê³µí†µ ì•ˆì „\",\n",
    "        \"purpose\": \"ëª¨ë“  ê³µì¢…ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì ìš©ë˜ëŠ” ì•ˆì „ ê¸°ì¤€ ì œê³µ.\",\n",
    "        \"covers\": [\"PPE\", \"í˜„ì¥ ì•ˆì „ ìˆ˜ì¹™\"],\n",
    "        \"common_accidents\": [\"ì¶”ë½\", \"ë‚™í•˜\"],\n",
    "        \"best_for_queries\": [\"í˜„ì¥ ì•ˆì „ìˆ˜ì¹™\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "BASE_PATH = \"/home/user/Desktop/jiseok/capstone/RAG/construction-safety-agent/data/DB\"\n",
    "\n",
    "for folder, desc in DESCRIPTIONS.items():\n",
    "    folder_path = os.path.join(BASE_PATH, folder)\n",
    "    output_path = os.path.join(folder_path, \"description.json\")\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"âŒ í´ë” ì—†ìŒ: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(desc, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"âœ… ìƒì„±ë¨: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiseok",
   "language": "python",
   "name": "ji_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
