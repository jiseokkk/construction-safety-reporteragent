from typing import List, Dict, Any, Tuple, Optional
from langchain_core.documents import Document
from core.advanced_document_processor import AdvancedDocumentProcessor
import chainlit as cl


class HumanFeedbackCollector:
    """RAG ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ Human-in-the-Loop í”¼ë“œë°± ìˆ˜ì§‘ (Chainlit)"""

    def __init__(self, enable_advanced_processing: bool = True):
        self.feedback_history = []
        self.enable_advanced_processing = enable_advanced_processing
        self.processor = (
            AdvancedDocumentProcessor() if enable_advanced_processing else None
        )

    # =====================================================================================
    # âœ… DOCXìš© ê·¼ê±° ìë£Œ ìƒì„± í•¨ìˆ˜
    # =====================================================================================
    def _build_source_references(
        self,
        docs: List[Document],
        processed_results: Optional[List[Dict[str, Any]]] = None,
    ) -> List[Dict[str, Any]]:

        refs = []
        iterable = processed_results or [{"doc": d} for d in docs]

        for idx, item in enumerate(iterable, 1):
            doc = item["doc"]
            md = getattr(doc, "metadata", {}) or {}

            refs.append(
                {
                    "idx": idx,
                    "filename": md.get("file")
                    or md.get("source")
                    or md.get("url")
                    or "ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì„œ",
                    "hierarchy": md.get("hierarchy_str", ""),
                    "section": (md.get("section") or "").replace("#", "").strip(),
                    "relevance_summary": item.get("relevance_summary", ""),
                    "key_sentences": item.get("key_sentences", []),
                }
            )

        return refs

    # =====================================================================================
    async def process(
        self, docs: List[Document], query: str, available_dbs: List[str]
    ) -> Tuple[List[Document], Dict[str, Any]]:

        if not docs:
            await cl.Message(content="âš ï¸ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.").send()
            return docs, {"action": "no_docs"}

        # --------------------------------------
        # Phase 3 ê³ ê¸‰ ì²˜ë¦¬
        # --------------------------------------
        processed_results = None
        if self.enable_advanced_processing and self.processor:
            processed_results = self.processor.process_documents(
                docs=docs,
                user_query=query,
                remove_duplicates=True,
                extract_key_sentences=True,
            )
            docs = [result["doc"] for result in processed_results]

        # --------------------------------------
        # ê·¼ê±° ëª©ë¡ ìë™ ìƒì„±
        # --------------------------------------
        source_references = self._build_source_references(docs, processed_results)

        # --------------------------------------
        # ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° UI
        # --------------------------------------
        await self._preview_documents_chainlit(docs, processed_results)

        # --------------------------------------
        # ì‚¬ìš©ì í–‰ë™ ì„ íƒ
        # --------------------------------------
        action = await self._get_user_action_chainlit_button()

        # =====================================================================================
        # ì„ íƒ ë¶„ê¸° â€” ëª¨ë“  return ê°’ì— source_references í¬í•¨
        # =====================================================================================

        # 1) ì „ì²´ ë¬¸ì„œ ì‚¬ìš©
        if action == "accept_all":
            await cl.Message(content="âœ… ëª¨ë“  ë¬¸ì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.").send()
            return (
                docs,
                {
                    "action": "accept_all",
                    "count": len(docs),
                    "web_search_requested": False,
                    "source_references": source_references,
                },
            )

        # 2) ì¼ë¶€ ë¬¸ì„œë§Œ ì„ íƒ
        elif action == "select_partial":
            selected_docs = await self._select_documents_chainlit(docs)
            if selected_docs:
                partial_refs = self._build_source_references(selected_docs)
                await cl.Message(
                    content=f"âœ‚ï¸ {len(selected_docs)}ê°œ ë¬¸ì„œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤."
                ).send()

                return (
                    selected_docs,
                    {
                        "action": "select_partial",
                        "count": len(selected_docs),
                        "web_search_requested": False,
                        "source_references": partial_refs,
                    },
                )
            else:
                return (
                    docs,
                    {
                        "action": "accept_all",
                        "count": len(docs),
                        "web_search_requested": False,
                        "source_references": source_references,
                    },
                )

        # 3) í‚¤ì›Œë“œ ì¬ê²€ìƒ‰
        elif action == "research_keyword":
            keywords = await self._get_additional_keywords_chainlit()
            return (
                docs,
                {
                    "action": "research_keyword",
                    "keywords": keywords,
                    "original_docs": docs,
                    "web_search_requested": False,
                    "source_references": source_references,
                },
            )

        # 4) ë‹¤ë¥¸ DBì—ì„œ ì¬ê²€ìƒ‰
        elif action == "research_db":
            selected_dbs = await self._select_databases_chainlit(available_dbs)
            return (
                docs,
                {
                    "action": "research_db",
                    "dbs": selected_dbs,
                    "original_docs": docs,
                    "web_search_requested": False,
                    "source_references": source_references,
                },
            )

        # 5) ì›¹ ê²€ìƒ‰ ìš”ì²­
        elif action == "web_search":
            await cl.Message(content="ğŸŒ ì›¹ ê²€ìƒ‰ ìš”ì²­ë¨.").send()
            return (
                docs,
                {
                    "action": "accept_all",
                    "count": len(docs),
                    "web_search_requested": True,
                    "source_references": source_references,
                },
            )

        # 6) ì·¨ì†Œ ë˜ëŠ” timeout
        return (
            docs,
            {
                "action": "accept_all",
                "count": len(docs),
                "web_search_requested": False,
                "source_references": source_references,
            },
        )

    # =====================================================================================
    # ì‚¬ìš©ì í–‰ë™ ì„ íƒ UI
    # =====================================================================================
    async def _get_user_action_chainlit_button(self) -> Optional[str]:

        actions = [
            cl.Action(
                name="action_1",
                value="accept_all",
                label="1ï¸âƒ£ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ì§„í–‰",
                payload={"action": "accept_all"},
            ),
            cl.Action(
                name="action_2",
                value="select_partial",
                label="2ï¸âƒ£ ì¼ë¶€ ë¬¸ì„œë§Œ ì„ íƒ",
                payload={"action": "select_partial"},
            ),
            cl.Action(
                name="action_3",
                value="research_keyword",
                label="3ï¸âƒ£ í‚¤ì›Œë“œ ì¶”ê°€ ì¬ê²€ìƒ‰",
                payload={"action": "research_keyword"},
            ),
            cl.Action(
                name="action_4",
                value="research_db",
                label="4ï¸âƒ£ ë‹¤ë¥¸ DBì—ì„œ ì¬ê²€ìƒ‰",
                payload={"action": "research_db"},
            ),
            cl.Action(
                name="action_5",
                value="web_search",
                label="5ï¸âƒ£ ì›¹ ê²€ìƒ‰ ì¶”ê°€ (Tavily)",
                payload={"action": "web_search"},
            ),
        ]

        res = await cl.AskActionMessage(
            content="ğŸ’¬ ë‹¤ìŒ ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”.", actions=actions, timeout=180
        ).send()

        if not res:
            return None

        return (
            res.get("value")
            or res.get("payload", {}).get("action")
            or res.get("name")
        )

    # =====================================================================================
    # ë¬¸ì„œ ì„ íƒ/ë¯¸ë¦¬ë³´ê¸° ë“± ë‚˜ë¨¸ì§€ í•¨ìˆ˜ â€” ê¸°ì¡´ ìœ ì§€
    # =====================================================================================

    async def _preview_documents_chainlit(
        self, docs: List[Document], processed_results: List[Dict] = None
    ):
        header = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š **RAG ê²€ìƒ‰ ê²°ê³¼ (HITL ê³ ê¸‰ ì²˜ë¦¬ ì ìš©)**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì´ **{len(docs)}ê°œ ë¬¸ì„œ**ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.
"""
        await cl.Message(content=header).send()

        for idx, doc in enumerate(docs, 1):
            metadata = doc.metadata
            content = doc.page_content

            file_name = metadata.get("file", "ì•Œ ìˆ˜ ì—†ìŒ")
            section = metadata.get("section", "")
            hierarchy = metadata.get("hierarchy_str", "")
            db = metadata.get("db", "ì•Œ ìˆ˜ ì—†ìŒ")

            score = metadata.get("score", 0)
            if score == 0:
                score = max(100 - (idx - 1) * 5, 50)

            if score >= 80:
                relevance_icon = "âœ… ë†’ìŒ"
            elif score >= 60:
                relevance_icon = "âš ï¸ ì¤‘ê°„"
            else:
                relevance_icon = "â“ ë‚®ìŒ"

            doc_info = f"""
**[{idx}] {relevance_icon}** (ê´€ë ¨ë„: {score}%)
ğŸ“„ íŒŒì¼: `{file_name}`
"""
            if hierarchy:
                doc_info += f"ğŸ“ ìœ„ì¹˜: {hierarchy}\n"
            if section:
                doc_info += f"ğŸ“Œ ì„¹ì…˜: {section}\n"

            doc_info += f"ğŸ—‚ï¸ DB: {db}\n"

            if processed_results and idx <= len(processed_results):
                r = processed_results[idx - 1]

                if r.get("relevance_summary"):
                    doc_info += f"\nğŸ’¡ ê´€ë ¨ì„±: {r['relevance_summary']}\n"

                if r.get("key_sentences"):
                    doc_info += "\nğŸ¯ í•µì‹¬ ë¬¸ì¥:\n"
                    for i, s in enumerate(r["key_sentences"], 1):
                        doc_info += f"   {i}) {s}\n"

            content_preview = (
                content[:800] + "...\n(800ì í‘œì‹œ)"
                if len(content) > 800
                else content
            )

            doc_info += f"""
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“ ì›ë¬¸:
{content_preview}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

            await cl.Message(content=doc_info).send()

        await cl.Message(content="â”" * 80).send()

    async def _select_documents_chainlit(
        self, docs: List[Document]
    ) -> List[Document]:

        msg = await cl.AskUserMessage(
            content=f"""
ğŸ“Œ ì‚¬ìš©í•  ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.

ì˜ˆì‹œ:
- `1,2,4,7`
- `1-5,8`

ì´ {len(docs)}ê°œ ë¬¸ì„œ ì¤‘ ì„ íƒ
""",
            timeout=180,
        ).send()

        if not msg:
            return []

        selection = msg["output"].strip()

        try:
            indices = self._parse_selection(selection, len(docs))
            return [docs[i - 1] for i in indices if 1 <= i <= len(docs)]
        except:
            return []

    def _parse_selection(self, selection: str, max_num: int) -> List[int]:

        indices = []

        for part in selection.split(","):
            part = part.strip()

            if "-" in part:
                s, e = part.split("-")
                indices.extend(range(int(s), int(e) + 1))
            else:
                indices.append(int(part))

        indices = sorted(set(indices))
        return [i for i in indices if 1 <= i <= max_num]

    async def _get_additional_keywords_chainlit(self) -> List[str]:
        msg = await cl.AskUserMessage(
            content="ğŸ” ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            timeout=180,
        ).send()

        if not msg:
            return []

        return [k.strip() for k in msg["output"].split(",") if k.strip()]

    async def _select_databases_chainlit(
        self, available_dbs: List[str]
    ) -> List[str]:

        db_list = "\n".join(
            [f"[{i}] {db}" for i, db in enumerate(available_dbs, 1)]
        )

        msg = await cl.AskUserMessage(
            content=f"""
ğŸ—‚ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ DB ëª©ë¡:

{db_list}

ğŸ“Œ ì‚¬ìš©í•  DB ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” ì˜ˆ) 1,3 ë˜ëŠ” 2-5
""",
            timeout=180,
        ).send()

        if not msg:
            return []

        try:
            idxs = self._parse_selection(msg["output"], len(available_dbs))
            return [available_dbs[i - 1] for i in idxs]
        except:
            return []
