# core/final_report.py (LLM Factory ì ìš©)
from core.agentstate import AgentState
import traceback
import os

# âœ… Factory Import
from core.llm_factory import get_llm

# âœ… LangChain ê´€ë ¨ ì„í¬íŠ¸
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# === 1. ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½ ìƒì„± ===
def summarize_accident_cause(rag_output: str, user_query: str) -> str:
    """
    RAG ê¸°ë°˜ ì‚¬ê³  ì •ë³´ë¥¼ ì´ìš©í•´ 'ì‚¬ê³ ë°œìƒ ê²½ìœ„' ìš”ì•½ (Qwen ì‚¬ìš©)
    """
    
    # âœ… Qwen(Fast) ëª¨ë¸ ì‚¬ìš© (ë³´ê³ ì„œ ì´ˆì•ˆ ì‘ì„±)
    llm = get_llm(mode="fast")
    
    system_template = """
ë‹¹ì‹ ì€ ê±´ì„¤ ì‚¬ê³  ì¡°ì‚¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì•ˆì „ê´€ë¦¬ ë‹´ë‹¹ìì…ë‹ˆë‹¤.
ì•„ë˜ ì œê³µë˜ëŠ” RAG ë¬¸ì„œì™€ ì‚¬ê³  ê°œìš” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ
'ì‚¬ê³ ë°œìƒ ê²½ìœ„(ë°œìƒì›ì¸)'ì„ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

[ì‘ì„± ê·œì¹™]
- RAG ë¬¸ì„œì— í¬í•¨ëœ ë‚´ìš©ë§Œ ì‚¬ìš© (ì™¸ë¶€ ì§€ì‹/ì¶”ì¸¡ ê¸ˆì§€)
- ì›ì¸ê³¼ ìƒí™©ì´ ë“œëŸ¬ë‚˜ë„ë¡ 4~6ì¤„ ì •ë„ë¡œ ì‘ì„±
- ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´, ì¥í™©í•œ ë°°ê²½ ì„¤ëª…ì€ ì¤„ì´ê³  í•µì‹¬ë§Œ ê¸°ìˆ 
- ë³´ê³ ì„œ ë¬¸ì²´(ì¡´ëŒ“ë§ X, ì„œìˆ í˜• ë¬¸ì¥)ë¡œ ì‘ì„±
"""
    
    user_template = """
[ì‚¬ê³  ê°œìš”]
{user_query}

[RAG ë¬¸ì„œ]
{rag_output}
"""

    try:
        print("ğŸ§  [LLM í˜¸ì¶œ] ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½ ìƒì„± ì¤‘...")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_template),
            ("user", user_template)
        ])
        
        # Qwenì€ temperature 0 ì¶”ì²œ
        chain = prompt | llm.bind(temperature=0.0) | StrOutputParser()
        
        text = chain.invoke({
            "user_query": user_query, 
            "rag_output": rag_output
        })

        if not text:
            print("âš ï¸ ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½ ìƒì„± ì‹¤íŒ¨")
            return "RAG ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ê³ ë°œìƒ ê²½ìœ„ë¥¼ ìš”ì•½í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        return text.strip()

    except Exception as e:
        print("âŒ ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ!")
        print(f"ì˜ˆì™¸ ë©”ì‹œì§€: {e}")
        return "ì‚¬ê³ ë°œìƒ ê²½ìœ„ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


# === 2. ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš ë³´ê³ ì„œ ìƒì„± ===
def generate_action_plan(rag_output: str, user_query: str, source_references: list = None) -> str:
    """
    'ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš' ìƒì„± (Qwen ì‚¬ìš©)
    """
    
    # âœ… Qwen(Fast) ëª¨ë¸ ì‚¬ìš©
    llm = get_llm(mode="smart")
    
    # ê·¼ê±° ìë£Œ ì •ë³´ êµ¬ì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    reference_info = ""
    if source_references and len(source_references) > 0:
        reference_info = "\n\n[ì°¸ì¡° ê°€ëŠ¥í•œ ê·¼ê±° ë¬¸ì„œ ëª©ë¡]\n"
        for ref in source_references:
            reference_info += f"- [ë¬¸ì„œ {ref['idx']}] {ref['filename']}"
            if ref.get('section'):
                reference_info += f" (ì„¹ì…˜: {ref['section']})"
            reference_info += "\n"
            
            if ref.get('key_sentences'):
                reference_info += "  í•µì‹¬ ë‚´ìš©:\n"
                for sentence in ref['key_sentences'][:2]:  # ì²˜ìŒ 2ê°œë§Œ
                    reference_info += f"  â€¢ {sentence}\n"
    
    system_template = """
ë‹¹ì‹ ì€ ê±´ì„¤í˜„ì¥ ì•ˆì „ê´€ë¦¬ ì±…ì„ìë¡œì„œ,
ìƒê¸‰ìì—ê²Œ ì œì¶œí•  'ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš' ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.

[ìš”êµ¬ì‚¬í•­]
- RAG ë¬¸ì„œ ë‚´ìš©ì„ ê·¼ê±°ë¡œ ì‚¬ìš©í•  ê²ƒ
- ë¬¸ë‹¨ êµ¬ì¡°ì™€ ë…¼ë¦¬ê°€ ë¶„ëª…í•´ì•¼ í•¨
- **ê° ì¡°ì¹˜ì‚¬í•­ë§ˆë‹¤ ì–´ë–¤ ë¬¸ì„œë¥¼ ê·¼ê±°ë¡œ í–ˆëŠ”ì§€ ëª…ì‹œí•  ê²ƒ** (ì˜ˆ: "ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì— ë”°ë¼...")
- í•œêµ­ì–´ ë³´ê³ ì„œ ë¬¸ì²´(ì„œìˆ í˜•)ë¡œ ì‘ì„±

[êµ¬ì„±]
1. ì¦‰ì‹œ ì¡°ì¹˜
2. ì›ì¸ ì œê±° ì¡°ì¹˜
3. ì¬ë°œ ë°©ì§€ ëŒ€ì±…
4. ê´€ë ¨ ê·¼ê±° ìš”ì•½

[ë¶„ëŸ‰]
- ìµœì†Œ 800ì ì´ìƒ ìƒì„¸íˆ ì‘ì„±
"""

    user_template = """
ì•„ë˜ëŠ” ì‚¬ê³  ê°œìš”ì™€ RAG ê¸°ë°˜ ê·¼ê±° ë¬¸ì„œì´ë‹¤.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš'ì„ ìœ„ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ì‘ì„±í•˜ë¼.

[ì‚¬ê³  ê°œìš”]
{user_query}

[ê·¼ê±°ê°€ ë˜ëŠ” RAG ë¬¸ì„œ]
{rag_output}

{reference_info}
"""

    try:
        print("ğŸ§  [LLM í˜¸ì¶œ] ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš ìƒì„± ì¤‘...")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_template),
            ("user", user_template)
        ])
        
        # Qwen Context Length ê³ ë ¤ (í•„ìš”ì‹œ max_tokens ì¡°ì ˆ)
        chain = prompt | llm.bind(temperature=0.1) | StrOutputParser()
        
        text = chain.invoke({
            "user_query": user_query,
            "rag_output": rag_output,
            "reference_info": reference_info
        })

        if not text:
            print("âš ï¸ ì¡°ì¹˜ì‚¬í•­ ìƒì„± ì‹¤íŒ¨")
            return "ì¡°ì¹˜ì‚¬í•­ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        return text.strip()

    except Exception as e:
        print("âŒ ì¡°ì¹˜ì‚¬í•­ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ!")
        print(f"ì˜ˆì™¸ ë©”ì‹œì§€: {e}")
        return "ì¡°ì¹˜ì‚¬í•­ì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


# === 3. (ì„ íƒ) LangGraph ìš© Node (ê¸°ì¡´ ìœ ì§€) ===
def generate_accident_report_node(state: AgentState) -> AgentState:
    """
    LangGraph í˜¸í™˜ìš© ë…¸ë“œ í•¨ìˆ˜
    """
    rag_output = state.get("docs_text") or state.get("rag_text") or ""
    user_query = state.get("user_query", "")

    # â‘  ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½
    summary_cause = summarize_accident_cause(rag_output, user_query)

    # â‘¡ ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš
    action_plan = generate_action_plan(
        rag_output,
        user_query,
        state.get("source_references", [])
    )

    # â‘¢ ìƒíƒœ ì—…ë°ì´íŠ¸
    combined = f"ã€ì‚¬ê³ ë°œìƒ ê²½ìœ„ã€‘\n{summary_cause}\n\nã€ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íšã€‘\n{action_plan}"

    state["summary_cause"] = summary_cause
    state["summary_action_plan"] = action_plan
    state["report_text"] = combined
    state["report"] = combined
    state["report_summary"] = (combined[:200] + "...") if len(combined) > 200 else combined
    state["route"] = "grade_report_quality"

    print("ğŸ§¾ [STATE UPDATE] ìš”ì•½/ì¡°ì¹˜ê³„íš ìƒì„± ì™„ë£Œ")

    return state