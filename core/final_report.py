# core/final_report.py (LangChain LCEL ì ìš© ë²„ì „)
from core.agentstate import AgentState
import traceback
import os

# âœ… LangChain ê´€ë ¨ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# LangChain LLM ì´ˆê¸°í™” (í•¨ìˆ˜ ë°–ì—ì„œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•˜ì—¬ ì¬ì‚¬ìš© ê¶Œì¥)
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.3, # ê¸°ì¡´ ì„¤ì • ìœ ì§€
    api_key=os.getenv("OPENAI_API_KEY")
)

# === 1. ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½ ìƒì„± ===
def summarize_accident_cause(rag_output: str, user_query: str) -> str:
    """
    RAG ê¸°ë°˜ ì‚¬ê³  ì •ë³´ë¥¼ ì´ìš©í•´ 'ì‚¬ê³ ë°œìƒ ê²½ìœ„(ë°œìƒì›ì¸)'ì„
    4~6ì¤„ ì •ë„ë¡œ ê°„ë‹¨Â·ëª…í™•í•˜ê²Œ ìš”ì•½. (LangChain LCEL ì ìš©)
    """
    
    system_template = """
ë‹¹ì‹ ì€ ê±´ì„¤ ì‚¬ê³  ì¡°ì‚¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì•ˆì „ê´€ë¦¬ ë‹´ë‹¹ìì…ë‹ˆë‹¤.
ì•„ë˜ ì œê³µë˜ëŠ” RAG ë¬¸ì„œì™€ ì‚¬ê³  ê°œìš” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ
'ì‚¬ê³ ë°œìƒ ê²½ìœ„(ë°œìƒì›ì¸)'ì„ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

[ì‘ì„± ê·œì¹™]
- RAG ë¬¸ì„œì— í¬í•¨ëœ ë‚´ìš©ë§Œ ì‚¬ìš© (ì™¸ë¶€ ì§€ì‹/ì¶”ì¸¡ ê¸ˆì§€)
- ì›ì¸ê³¼ ìƒí™©ì´ ë“œëŸ¬ë‚˜ë„ë¡ 4~6ì¤„ ì •ë„ë¡œ ì‘ì„±
- ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´, ì¥í™©í•œ ë°°ê²½ ì„¤ëª…ì€ ì¤„ì´ê³  í•µì‹¬ë§Œ ê¸°ìˆ 
- ë³´ê³ ì„œ ë¬¸ì²´(ì¡´ëŒ“ë§ X, ì„œìˆ í˜• ë¬¸ì¥)ë¡œ ì‘ì„±
"""
    
    user_template = """
[ì‚¬ê³  ê°œìš”]
{user_query}

[RAG ë¬¸ì„œ]
{rag_output}
"""

    try:
        print("ğŸ§  [LLM í˜¸ì¶œ] ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½ ìƒì„± ì¤‘...")
        
        # ğŸ”¥ LCEL Chain êµ¬ì„±
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_template),
            ("user", user_template)
        ])
        
        # temperature=0.2ë¡œ ì„¤ì •ëœ ë³„ë„ ì²´ì¸ ì‚¬ìš© (ê¸°ì¡´ ë¡œì§ ì¤€ìˆ˜)
        chain = prompt | llm.bind(temperature=0.2, top_p=0.9, max_tokens=1600) | StrOutputParser()
        
        # ì‹¤í–‰
        text = chain.invoke({
            "user_query": user_query, 
            "rag_output": rag_output
        })

        if not text or "âš ï¸" in text:
            print("âš ï¸ ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½ ìƒì„± ì‹¤íŒ¨:", text)
            return "RAG ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ê³ ë°œìƒ ê²½ìœ„ë¥¼ ìš”ì•½í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        return text.strip()

    except Exception as e:
        print("âŒ ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ!")
        print(f"ì˜ˆì™¸ íƒ€ì…: {type(e).__name__}")
        print(f"ì˜ˆì™¸ ë©”ì‹œì§€: {e}")
        print(traceback.format_exc())
        return "ì‚¬ê³ ë°œìƒ ê²½ìœ„ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


# === 2. ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš ë³´ê³ ì„œ ìƒì„± ===
def generate_action_plan(rag_output: str, user_query: str, source_references: list = None) -> str:
    """
    'ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš'ì„ ìƒì‚¬ ë³´ê³ ìš© ê³ í’ˆì§ˆ í…ìŠ¤íŠ¸ë¡œ ìƒì„±.
    (LangChain LCEL ì ìš©)
    """
    
    # âœ… ê·¼ê±° ìë£Œ ì •ë³´ êµ¬ì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    reference_info = ""
    if source_references and len(source_references) > 0:
        reference_info = "\n\n[ì°¸ì¡° ê°€ëŠ¥í•œ ê·¼ê±° ë¬¸ì„œ ëª©ë¡]\n"
        for ref in source_references:
            reference_info += f"- [ë¬¸ì„œ {ref['idx']}] {ref['filename']}"
            if ref.get('section'):
                reference_info += f" (ì„¹ì…˜: {ref['section']})"
            reference_info += "\n"
            
            if ref.get('key_sentences'):
                reference_info += "  í•µì‹¬ ë‚´ìš©:\n"
                for sentence in ref['key_sentences'][:2]:  # ì²˜ìŒ 2ê°œë§Œ
                    reference_info += f"  â€¢ {sentence}\n"
    
    system_template = """
ë‹¹ì‹ ì€ ê±´ì„¤í˜„ì¥ ì•ˆì „ê´€ë¦¬ ì±…ì„ìë¡œì„œ,
ìƒê¸‰ì(ë¶€ì„œì¥ ë˜ëŠ” ë°œì£¼ì²˜)ì— ì œì¶œí•  'ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš' ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.

[ì „ë°˜ì ì¸ ìš”êµ¬ì‚¬í•­]
- ì‹¤ì œ ë³´ê³ ì„œ ë¬¸ì„œì— ê·¸ëŒ€ë¡œ ì‚½ì…í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì˜ ì™„ì„±ë„ë¥¼ ê°–ì¶œ ê²ƒ
- RAG ë¬¸ì„œì— í¬í•¨ëœ ë‚´ìš©ë§Œ ê·¼ê±°ë¡œ ì‚¬ìš© (ì™¸ë¶€ ì§€ì‹ ì¶”ê°€ ê¸ˆì§€)
- ë¬¸ë‹¨ êµ¬ì¡°ì™€ ë…¼ë¦¬ê°€ ë¶„ëª…í•´ì•¼ í•¨ (ë‹¨ìˆœ bullet ë‚˜ì—´ ê¸ˆì§€)
- âœ… **ê° ì¡°ì¹˜ì‚¬í•­ë§ˆë‹¤ ì–´ë–¤ ë¬¸ì„œë¥¼ ê·¼ê±°ë¡œ í–ˆëŠ”ì§€ ëª…ì‹œí•  ê²ƒ**
  ì˜ˆ: "ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì— ê´€í•œ ê·œì¹™ì— ë”°ë¥´ë©´..."
  ì˜ˆ: "êµëŸ‰ê³µì‚¬ ì•ˆì „ì‘ì—…ì§€ì¹¨(ë¬¸ì„œ 1)ì— ëª…ì‹œëœ ë°”ì™€ ê°™ì´..."
- í•œêµ­ì–´ ë³´ê³ ì„œ ë¬¸ì²´(ì„œìˆ í˜•)ë¡œ ì‘ì„±í•  ê²ƒ

[êµ¬ì„±]
1. ì¦‰ì‹œ ì¡°ì¹˜ (Immediate Action)
   - ê° ì¡°ì¹˜ì˜ ê·¼ê±° ë¬¸ì„œ ëª…ì‹œ
   
2. ì›ì¸ ì œê±° ì¡°ì¹˜ (Corrective Action)
   - ê° ì¡°ì¹˜ì˜ ê·¼ê±° ë¬¸ì„œ ëª…ì‹œ
   
3. ì¬ë°œ ë°©ì§€ ëŒ€ì±… (Preventive Action)
   - ê° ì¡°ì¹˜ì˜ ê·¼ê±° ë¬¸ì„œ ëª…ì‹œ
   
4. ê´€ë ¨ ê·¼ê±° ìš”ì•½
   - ì£¼ìš” ì°¸ì¡° ë¬¸ì„œ ë° ì¡°í•­ ì •ë¦¬

[ê·¼ê±° ëª…ì‹œ ì˜ˆì‹œ]
"êµëŸ‰ê³µì‚¬(ë¼ë©˜êµ) ì•ˆì „ë³´ê±´ì‘ì—…ì§€ì¹¨(ë¬¸ì„œ 1)ì— ë”°ë¥´ë©´, ë†’ì´ 4ë¯¸í„°ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ìˆ˜í‰ì—°ê²°ì¬ë¥¼ ì„¤ì¹˜í•˜ë„ë¡ ê·œì •í•˜ê³  ìˆë‹¤. ë”°ë¼ì„œ..."

[ë¶„ëŸ‰]
- ìµœì†Œ 800ì ì´ìƒ, ê°€ëŠ¥í•˜ë©´ 1200~1800ì ë‚´ì™¸ë¡œ ì¶©ë¶„íˆ ìƒì„¸íˆ ì‘ì„±
- ê° í•­ëª©ì€ í•˜ë‚˜ ì´ìƒì˜ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±
"""

    user_template = """
ì•„ë˜ëŠ” ì‚¬ê³  ê°œìš”ì™€ RAG ê¸°ë°˜ ê·¼ê±° ë¬¸ì„œì´ë‹¤.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš'ì„ ìœ„ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ì‘ì„±í•˜ë¼.

**ì¤‘ìš”: ê° ì¡°ì¹˜ì‚¬í•­ì„ ì œì‹œí•  ë•Œ, ë°˜ë“œì‹œ ì–´ë–¤ ë¬¸ì„œë¥¼ ê·¼ê±°ë¡œ í–ˆëŠ”ì§€ ëª…ì‹œí•˜ë¼.**

[ì‚¬ê³  ê°œìš”]
{user_query}

[ê·¼ê±°ê°€ ë˜ëŠ” RAG ë¬¸ì„œ]
{rag_output}

{reference_info}
"""

    try:
        print("ğŸ§  [LLM í˜¸ì¶œ] ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš ìƒì„± ì¤‘ (ê·¼ê±° ëª…ì‹œ í¬í•¨)...")
        
        # ğŸ”¥ LCEL Chain êµ¬ì„±
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_template),
            ("user", user_template)
        ])
        
        # temperature=0.3 ì„¤ì • (ê¸°ì¡´ ë¡œì§ ì¤€ìˆ˜)
        chain = prompt | llm.bind(temperature=0.3, top_p=0.9, max_tokens=4000) | StrOutputParser()
        
        # ì‹¤í–‰
        text = chain.invoke({
            "user_query": user_query,
            "rag_output": rag_output,
            "reference_info": reference_info
        })

        if not text or "âš ï¸" in text:
            print("âš ï¸ ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš ìƒì„± ì‹¤íŒ¨:", text)
            return "RAG ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íšì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        return text.strip()

    except Exception as e:
        print("âŒ ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ!")
        print(f"ì˜ˆì™¸ íƒ€ì…: {type(e).__name__}")
        print(f"ì˜ˆì™¸ ë©”ì‹œì§€: {e}")
        print(traceback.format_exc())
        return "ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íšì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


# === 3. (ì„ íƒ) LangGraph ìš© Node - í˜¸í™˜ìš© (ê¸°ì¡´ ìœ ì§€) ===
def generate_accident_report_node(state: AgentState) -> AgentState:
    """
    LangGraphì—ì„œ í˜¸ì¶œë˜ëŠ” ë³´ê³ ì„œ ìƒì„± ë…¸ë“œ.
    - summary_cause
    - summary_action_plan
    ì„ ìƒì„±í•˜ê³ , report_textì— í•©ì³ë‘”ë‹¤.
    """
    rag_output = state.get("docs_text") or state.get("rag_text") or ""
    user_query = state.get("user_query", "")

    # â‘  ì‚¬ê³ ë°œìƒ ê²½ìœ„ ìš”ì•½
    summary_cause = summarize_accident_cause(rag_output, user_query)

    # â‘¡ ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íš
    action_plan = generate_action_plan(
        rag_output,
        user_query,
        state.get("source_references", [])     # â­ ê·¼ê±°ìë£Œ ì „ë‹¬
    )

    # â‘¢ ìƒíƒœ ì—…ë°ì´íŠ¸
    combined = f"ã€ì‚¬ê³ ë°œìƒ ê²½ìœ„ã€‘\n{summary_cause}\n\nã€ì¡°ì¹˜ì‚¬í•­ ë° í–¥í›„ì¡°ì¹˜ê³„íšã€‘\n{action_plan}"

    state["summary_cause"] = summary_cause
    state["summary_action_plan"] = action_plan
    state["report_text"] = combined
    state["report"] = combined
    state["report_summary"] = (combined[:200] + "...") if len(combined) > 200 else combined
    state["route"] = "grade_report_quality"

    print("ğŸ§¾ [STATE UPDATE] ìš”ì•½/ì¡°ì¹˜ê³„íš ìƒì„± ì™„ë£Œ")

    return state